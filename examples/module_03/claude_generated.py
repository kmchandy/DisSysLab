# Tech News Aggregator
# Topology: hacker_news â”€â”
#                         â”œâ†’ sentiment â†’ email_alert
#           tech_news   â”€â”˜           â†˜ file_collector

from dsl import network
from dsl.blocks import Source, Transform, Sink
from components.sources.demo_rss_source import DemoRSSSource
from components.transformers.prompts import SENTIMENT_ANALYZER
from components.transformers.demo_ai_agent import demo_ai_agent
from components.sinks import MockEmailAlerter, JSONLRecorder

# â”€â”€â”€ Data sources â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
hn = DemoRSSSource(feed_name="hacker_news")
tech = DemoRSSSource(feed_name="tech_news")

# â”€â”€â”€ AI component (demo â€” no API key needed) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
sentiment_analyzer = demo_ai_agent(SENTIMENT_ANALYZER)

# â”€â”€â”€ Transform function â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def analyze_sentiment(text):
    """Tag each article with its sentiment and score."""
    result = sentiment_analyzer(text)
    return {
        "text":      text,
        "sentiment": result["sentiment"],   # POSITIVE / NEGATIVE / NEUTRAL
        "score":     result["score"],
    }

# â”€â”€â”€ Output functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def email_display(article):
    """Print a mock email alert for each article."""
    icons = {"POSITIVE": "ğŸ˜Š", "NEGATIVE": "ğŸ˜", "NEUTRAL": "ğŸ˜"}
    icon = icons.get(article["sentiment"], "â“")
    print(f"  ğŸ“§ {icon} [{article['sentiment']:8s}]  {article['text']}")


# â”€â”€â”€ Sinks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
recorder = JSONLRecorder(
    path="news_results.jsonl",
    mode="w",
    flush_every=1,
    name="news_archive",
)

# â”€â”€â”€ Build the network â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
hn_source = Source(fn=hn.run,             name="hacker_news")
tech_source = Source(fn=tech.run,           name="tech_news")
sentiment = Transform(fn=analyze_sentiment, name="sentiment")
email_sink = Sink(fn=email_display,        name="email_alert")
file_sink = Sink(fn=recorder.run,         name="file_collector")

g = network([
    (hn_source,   sentiment),   # â”€â” fanin: both feeds
    (tech_source, sentiment),   # â”€â”˜ merge into sentiment
    (sentiment,   email_sink),  # â”€â” fanout: results go to
    (sentiment,   file_sink),   # â”€â”˜ both sinks simultaneously
])

if __name__ == "__main__":
    print("\nğŸ“° Tech News Aggregator")
    print("   hacker_news â”€â”")
    print("                â”œâ†’ sentiment â”€â”¬â†’ email_alert")
    print("   tech_news   â”€â”˜             â””â†’ file_collector\n")
    g.run_network()
    print("\nâœ… Done! Results saved to news_results.jsonl")
