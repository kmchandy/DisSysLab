{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DisSysLab Docs","text":""},{"location":"#start-here","title":"Start here","text":"<p>1) Module 1 \u2014 Intro \u2192 modules/ch01_networks/README_1.md 2) Module 2 \u2014 Sources \u2192 modules/ch02_sources/README_1.md 3) Module 3 \u2014 OpenAI agents \u2192 modules/ch03_GPT/README_1.md 4) Module 4 \u2014 Numerics \u2192 modules/ch04_numeric/README.md</p>"},{"location":"modules/ch01_networks/README_1/","title":"Module 1 \u2014 Intro","text":""},{"location":"modules/ch01_networks/README_1/#11-a-directed-graph-in-which-nodes-are-python-functions","title":"\ud83e\udde9 1.1 A Directed Graph in which Nodes are Python functions","text":""},{"location":"modules/ch01_networks/README_1/#goal","title":"\ud83c\udfaf Goal","text":""},{"location":"modules/ch01_networks/README_1/#-build-a-distributed-application-by-creating-a-network-which-is-directed-graph-in-which-nodes-are-agents-that-process-messages-and-edges-are-channels-along-which-messages-flow-agents-execute-concurrently","title":"- Build a distributed application by creating a network which is directed graph in which nodes are agents that process messages and edges are channels along which messages flow. Agents execute concurrently.","text":""},{"location":"modules/ch01_networks/README_1/#example","title":"\ud83d\udcbb Example","text":"<pre><code># modules.ch01_networks.basic_network.py\n\nfrom dsl import network\n\ndef from_list():\n    for item in [\"hello\", \"world\"]:\n        yield item\n\ndef uppercase(v):\n    return v.upper()\n\nresults = []\n\ndef to_results(x):\n    results.append(x)\n\n\ng = network([(from_list, uppercase), (uppercase, to_results)])\n\ng.run_network()\nprint(results)  # Output: ['HELLO', 'WORLD']\n\n</code></pre>"},{"location":"modules/ch01_networks/README_1/#network","title":"\ud83d\udccd Network","text":"<p>A network is specified by the list of edges of a directed graph. An edge is an ordered pair (u, v) which is an edge from node u to node v. Every node in the network has at least one incident edge. </p> <p>This example has two edges: <code>(from_list, uppercase)</code> and <code>(uppercase, to_results)</code> and  3 nodes: <code>from_list</code>, <code>uppercase</code>, and <code>to_results</code>. The name of a node is the name of the function (a \"callable\" in Python) that is executed by the node. </p> <p>The node <code>from_list</code> is a source. A source function has no parameters. A source function is an iterator which generates a sequence of values. Each execution of yield generates another value. In this example the iterator <code>from_list</code> yields two values: \"hello\" and \"world\". In many applications the number of values generated by a source is unbounded. For example, a source such as a temperature sensor generates measurements forever.</p> <p>The node <code>uppercase</code> is a transformer. A transformer function has a single parameter and returns a single value.  In this example, the function <code>uppercase</code> has a single parameter <code>v</code> and returns a single value <code>v.upper()</code>.</p> <p>The node <code>to_results</code> is a sink. A sink function has a single parameter. The function <code>to_results</code> has a single parameter <code>x</code> and execution of the function appends <code>x</code> to the list <code>results</code>.</p> <p>A source has no input edges and has at least one output edge. A transformer node has at least one input edge and a least one output edge. A sink node has no output edges and at least one input edge. Messages sent along an edge are received in the order in which they are sent.</p> <p>In this example, messages generated by from_list are sent to uppercase, and messages sent by uppercase are sent to to_results. Because messages are received in the order sent, <code>results</code> is ['HELLO', 'WORLD'] and not ['WORLD', 'HELLO'].</p>"},{"location":"modules/ch01_networks/README_1/#key-concepts","title":"\ud83e\udde0 Key Concepts","text":"<ul> <li> <p>A network is a directed graph in which nodes are agents that process messages which flow along edges.</p> </li> <li> <p>A source is specified by a function which is any iterator. A source has no inputs.</p> </li> <li> <p>A transformer is specified by a function which has a single input and a single output.</p> </li> <li> <p>A sink is specified by a function which has a single input and no outputs.</p> </li> <li> <p>Messages sent along an edge are received in the order sent.</p> </li> </ul>"},{"location":"modules/ch01_networks/README_1/#the-central-takeaway","title":"\ud83e\udde0 THE CENTRAL TAKEAWAY","text":"<p>The functions that define the nodes of the network are ordinary functions. They do not use threads, processes, queues or message send/receive operations.</p> <p>You develop a distributed application in DisSysLab by connecting functions. You often find the functions that you need in libraries such as Scikit or from AI-assisted software tools. In many cases you will use LLM (Large Language Model) functions by using prompts from a prompt library or writing your own.</p>"},{"location":"modules/ch01_networks/README_1/#next","title":"\ud83d\udc49 Next","text":"<p>Develop networks with fanout (the output of node is connected to the inputs of two or more nodes) and fanin (the input of a node is connected to the outputs of more than one node).</p>"},{"location":"modules/ch01_networks/README_2/","title":"README 2","text":""},{"location":"modules/ch01_networks/README_2/#12-fanout-and-fanin","title":"\ud83e\udde9 1.2 Fanout and Fanin","text":""},{"location":"modules/ch01_networks/README_2/#goal","title":"\ud83c\udfaf Goal","text":""},{"location":"modules/ch01_networks/README_2/#-understand-behavior-of-fanout-multiple-output-edges-from-a-node-and-fanin-multiple-input-edges-to-a-node","title":"- Understand behavior of fanout (multiple output edges from a node) and fanin (multiple input edges to a node.)","text":""},{"location":"modules/ch01_networks/README_2/#example-of-fanout","title":"\ud83d\udcbb Example of fanout","text":"<pre><code># modules.ch01_networks.simple_broadcast\n\nfrom dsl import network\n\ndef from_list():\n    for item in [\"hello\", \"world\"]:\n        yield item\n\nresults_0 = []\nresults_1 = []\n\n\ndef sink_0(item):\n    results_0.append(item)\n\n\ndef sink_1(item):\n    results_1.append(item)\n\n\n# Define the network as a list of directed edges of a graph\ng = network([(from_list, sink_0), (from_list, sink_1)])\ng.run_network()\n\nprint(results_0)    # Output: ['hello', 'world']\nprint(results_1)    # Output: ['hello', 'world']\n</code></pre>"},{"location":"modules/ch01_networks/README_2/#fanout","title":"\ud83d\udccd Fanout","text":"<p>The messages output by a node are broadcast along each of the node's output edges.</p>"},{"location":"modules/ch01_networks/README_2/#example-of-fanin","title":"\ud83d\udcbb Example of fanin","text":"<pre><code># modules.ch01_networks.simple_merge\n\nfrom dsl import network\nimport time\n\n\ndef from_list_0():\n    for item in [\"A\", \"B\"]:\n        yield item\n        time.sleep(0.06)\n\n\ndef from_list_1():\n    for item in [\"X\", \"Y\", \"Z\"]:\n        yield item\n        time.sleep(0.05)\n\n\nresults = []\ndef to_results(v): results.append(v)\n\n\ng = network([(from_list_0, to_results), (from_list_1, to_results)])\ng.run_network()\n\nprint(results)\nassert set(results) == {\"A\", \"B\", \"X\", \"Y\", \"Z\"}\n</code></pre>"},{"location":"modules/ch01_networks/README_2/#fanin","title":"\ud83d\udccd Fanin","text":"<p>The messages arriving along multiple edges at a node are merged nondeterministically and fairly. Messages sent along an edge arrive at the destination node eventually. The time that a message takes in transit along an edge is unknown. Even if message \"X\" is sent along the edge (from_list_1, to_results) before message \"A\" is sent along the edge (from_list_0, to_results) it is possible that \"A\" arrives at to_results before \"X\" does.</p>"},{"location":"modules/ch01_networks/README_2/#key-concepts","title":"\ud83e\udde0 Key Concepts","text":"<ul> <li>Fanout is a broadcast.</li> <li>Fanin is a fair merge.</li> </ul>"},{"location":"modules/ch01_networks/README_2/#next","title":"\ud83d\udc49 Next","text":"<p>Drop messages in streams by returning <code>None</code>.</p>"},{"location":"modules/ch01_networks/README_3/","title":"README 3","text":""},{"location":"modules/ch01_networks/README_3/#13-filtering-message-streams","title":"\ud83e\udde9 1.3 Filtering Message Streams","text":""},{"location":"modules/ch01_networks/README_3/#goal","title":"\ud83c\udfaf Goal","text":""},{"location":"modules/ch01_networks/README_3/#-drop-messages-in-streams-by-returning-none","title":"- Drop messages in streams by returning <code>None</code>.","text":""},{"location":"modules/ch01_networks/README_3/#example-of-dropping-messages","title":"\ud83d\udcbb Example of dropping messages","text":"<pre><code># modules.ch01_networks.simple_filter\n\nfrom dsl import network\n\n# Define functions.\n\nlist_of_words = ['t', 'hello', 'world', 'python', 'philosophy', 'is', 'fun']\n\n\ndef from_list(items=list_of_words):\n    for item in items:\n        yield item\n\n\ndef drop(v, min_length=2, max_length=8):\n    return v if min_length &lt;= len(v) &lt;= max_length else None\n\n\nresults = []\ndef to_results(v): results.append(v)\n\n\n# Define the network.\ng = network([(from_list, drop), (drop, to_results)])\ng.run_network()\n\nprint(results)\nassert results == ['hello', 'world', 'python', 'is', 'fun']\n</code></pre>"},{"location":"modules/ch01_networks/README_3/#filtering-streams","title":"\ud83d\udccd Filtering Streams","text":"<p>Transform functions return a value. If the value is <code>`None</code> then the value is not sent. This mechanism can be used to filter message streams.</p>"},{"location":"modules/ch01_networks/README_3/#key-concepts","title":"\ud83e\udde0 Key Concepts","text":"<ul> <li><code>None</code> is not sent as a message</li> <li>Filtering streams</li> </ul>"},{"location":"modules/ch01_networks/README_3/#next","title":"\ud83d\udc49 Next","text":"<p>Nodes add fields to messages and thus enrich messages as they flow through the network.</p>"},{"location":"modules/ch01_networks/README_4/","title":"README 4","text":""},{"location":"modules/ch01_networks/README_4/#14-pattern-enrich-messages-at-nodes","title":"\ud83e\udde9 1.4  Pattern: Enrich Messages at Nodes","text":""},{"location":"modules/ch01_networks/README_4/#goal","title":"\ud83c\udfaf Goal","text":""},{"location":"modules/ch01_networks/README_4/#-using-dictionaries-dict-to-enrich-messages-as-they-flow-through-a-network","title":"- Using dictionaries (<code>dict</code>) to enrich messages as they flow through a network.","text":""},{"location":"modules/ch01_networks/README_4/#example-of-enriching-messages-adding-fields","title":"\ud83d\udcbb Example of enriching messages (adding fields)","text":"<pre><code># modules.ch01_networks.simple_dict\n\nfrom dsl import network\n\nlist_of_words = ['hello', 'world', 'python']\n\n\ndef from_list(items=list_of_words):\n    for item in items:\n        yield {'text': item}\n\n\ndef exclaim(msg):\n    msg['exclaim'] = msg.get('text', '') + '!'\n    return msg\n\n\ndef uppercase(msg):\n    msg['uppercase'] = msg.get('text', '').upper()\n    return msg\n\n\nresults = []\ndef to_results(v): results.append(v)\n\n\n# Define the network.\ng = network([(from_list, exclaim), (exclaim, uppercase),\n            (uppercase, to_results)])\ng.run_network()\n\nassert results == [\n    {'text': 'hello', 'exclaim': 'hello!', 'uppercase': 'HELLO'},\n    {'text': 'world', 'exclaim': 'world!', 'uppercase': 'WORLD'},\n    {'text': 'python', 'exclaim': 'python!', 'uppercase': 'PYTHON'}\n]\n</code></pre>"},{"location":"modules/ch01_networks/README_4/#enriching-messages","title":"\ud83d\udccd Enriching Messages","text":"<p>A common pattern is to represent a message as a dict and have nodes add fields as they process it. This becomes especially useful with AI agents:</p> <p>Example: a topic-extractor adds <code>msg[\"topics\"] = [...]</code>.</p> <p>Then a sentiment step adds <code>msg[\"sentiment\"] = -1 | 0 | 1</code>.</p>"},{"location":"modules/ch01_networks/README_4/#key-concepts","title":"\ud83e\udde0 Key Concepts","text":"<ul> <li>Messages as dicts make enrichment easy: read \u2192 compute \u2192 attach \u2192 pass on.</li> </ul>"},{"location":"modules/ch01_networks/README_4/#next","title":"\ud83d\udc49 Next","text":"<p>Agents should not concurrently modify mutable objects.  </p> <p>Later in the course we will describe methods by which agents can share mutable objects. These methods ensure that (1) at most one agent reads or writes a mutable object at a time and (2) all agents that are waiting to read or write a mutable object gets to do so eventually.</p>"},{"location":"modules/ch01_networks/README_5/","title":"README 5","text":""},{"location":"modules/ch01_networks/README_5/#15-sharing-mutable-objects","title":"\ud83e\udde9 1.5 Sharing Mutable Objects","text":""},{"location":"modules/ch01_networks/README_5/#goal","title":"\ud83c\udfaf Goal","text":""},{"location":"modules/ch01_networks/README_5/#-understand-the-danger-of-multiple-agents-concurrently-modifying-mutable-objects-later-in-the-course-we-will-describe-methods-for-safe-sharing-of-mutables","title":"- Understand the danger of multiple agents concurrently modifying mutable objects. Later in the course we will describe methods for safe sharing of mutables.","text":""},{"location":"modules/ch01_networks/README_5/#example-dont-modify-mutables-concurrently","title":"\ud83d\udcbb Example: Don't modify mutables concurrently","text":"<pre><code># modules.ch01_networks.mutables\n\nfrom dsl import network\n\n\nclass AgentA:\n    def __init__(self):\n        self.my_list = []  # A's local state\n\n    def run(self, msg):\n        # \u274c BUG: A publishes *its local list object* into the message\n        msg[\"notes\"] = self.my_list\n        msg[\"notes\"].append(\"A1\")  # mutate (also mutates A.my_list)\n        return msg\n\n\nclass AgentB:\n    def __init__(self):\n        self.my_list = []  # B's local state\n\n    def run(self, msg):\n        # \u274c BUG: B *adopts the same object* from the message\n        self.my_list = msg[\"notes\"]   # alias, not a copy\n        # mutate (also mutates A.my_list and B.my_list)\n        msg[\"notes\"].append(\"B1\")\n        return msg\n\n\na, b = AgentA(), AgentB()\ndef run_A(msg): return a.run(msg)\ndef run_B(msg): return b.run(msg)\n\n\ndef src():\n    yield {}  # empty message to start\n\n\ndef snk(msg):\n    print(\"msg.notes:\", msg[\"notes\"], \" id:\", id(msg[\"notes\"]))\n    print(\"A.my_list:\", a.my_list,     \" id:\", id(a.my_list))\n    print(\"B.my_list:\", b.my_list,     \" id:\", id(b.my_list))\n    # All three ids match \u2192 it's the SAME object\n    # \n    # msg.notes: ['A1', 'B1']\n    # A.my_list: ['A1', 'B1']\n    # B.my_list: ['A1', 'B1']\n\n\ng = network([(src, run_A), (run_A, run_B), (run_B, snk)])\ng.run_network()\n</code></pre>"},{"location":"modules/ch01_networks/README_5/#concurrent-modification-of-mutables","title":"\ud83d\udccd Concurrent Modification of Mutables","text":"<p>Some applications require mutable objects, such as files, to be shared by multiple agents. In such applications the operating system (or supervising program) ensures that (1) at most one agent accesses the object at a time and (2) all agents that require access to the object get access to it eventually. We discuss sharing mutable agents later. Now let's look at problems that arise when mutable objects are modified concurrently.</p> <p>In this example, agent <code>a</code> appends \"A1\" to <code>msg['notes']</code> and takes no other action. So you may think that <code>a.my_list</code> is either <code>[]</code> or <code>['A1']</code>. But when the program terminates <code>a.my_list = ['A1', 'B1']</code> because when agent <code>b</code> modifies <code>msg['notes']</code> it also modifies <code>a.my_list</code>.</p>"},{"location":"modules/ch01_networks/README_5/#safe-use-of-data-by-multiple-agents","title":"\ud83d\udccd Safe Use of Data by Multiple Agents","text":"<ul> <li> <p>Send a copy: <code>msg[\"notes\"] = list(self.my_list)</code>. This makes <code>msg[\"notes\"]</code> a copy of <code>self.my_list</code>, and so modifying <code>msg[\"notes\"]</code> does not modify <code>self.my_list</code>.</p> </li> <li> <p>Read a copy of a message: <code>self.my_list = list(msg[\"notes\"])</code>.</p> </li> <li> <p>Note that as you saw in the previous lesson: You can enrich a message, by adding fields to the message without otherwise modifying the message.</p> </li> </ul>"},{"location":"modules/ch01_networks/README_5/#key-concepts","title":"\ud83e\udde0 Key Concepts","text":"<ul> <li>Beware of aliasing with mutables passed through messages.</li> </ul>"},{"location":"modules/ch01_networks/README_5/#-if-you-need-independent-state-copy-before-mutate-or-use-immutables","title":"- If you need independent state, copy before mutate (or use immutables).","text":""},{"location":"modules/ch01_networks/README_5/#next","title":"\ud83d\udc49 Next","text":"<p>Example of a network with fanout and fanin. </p>"},{"location":"modules/ch01_networks/README_6/","title":"\ud83d\udd78 1.6 \u2022 Simple Network \u2014 Fan-Out &amp; Fan-In","text":"<p>This page shows how to build an arbitrary graph (not just a linear pipeline) with fan-out (one node \u2192 many) and fan-in (many \u2192 one).</p>"},{"location":"modules/ch01_networks/README_6/#goal","title":"\ud83c\udfaf Goal","text":"<ul> <li>Create a small network with two sources that fan-out to two transforms and then fan-in to a single sink.</li> <li>Observe interleaved outputs as items flow concurrently from multiple sources.</li> </ul>"},{"location":"modules/ch01_networks/README_6/#example-arbitrary-graph-with-fan-out-fan-in","title":"\ud83d\udcbb Example: Arbitrary Graph with Fan-Out / Fan-In","text":"<pre><code># modules.ch01_networks.simple_network\n\nfrom dsl import network\nimport time\n\n# -----------------------------------------------------------\n# Sources\n# -----------------------------------------------------------\n\ndef from_list_0():\n    for item in [\"A\", \"B\"]:\n        yield item\n        time.sleep(0.12)\n\ndef from_list_1():\n    for item in [\"X\", \"Y\", \"Z\"]:\n        yield item\n        time.sleep(0.1)\n\n# -----------------------------------------------------------\n# Transforms\n# -----------------------------------------------------------\n\ndef lower(v):\n    return v.lower()\n\ndef add_bangs(v):\n    return v + \"!!\"\n\n# -----------------------------------------------------------\n# Sink (fan-in target)\n# -----------------------------------------------------------\n\nresults = []\ndef to_results(v): \n    results.append(v)\n\n# -----------------------------------------------------------\n# Graph wiring\n# - Fan OUT: each source feeds BOTH transforms\n# - Fan IN: both transforms feed the SAME sink\n# -----------------------------------------------------------\n\ng = network([\n    (from_list_0, lower), \n    (from_list_1, lower),\n    (from_list_0, add_bangs), \n    (from_list_1, add_bangs),\n    (lower, to_results), \n    (add_bangs, to_results)\n])\n\ng.run_network()\n\nif __name__ == \"__main__\":\n    print(set(results))\n    assert set(results) == {\"A!!\", \"B!!\", \"X!!\", \"Y!!\", \"Z!!\", \"a\", \"b\", \"x\", \"y\", \"z\"}\n</code></pre>"},{"location":"modules/ch01_networks/README_6/#run-the-demo","title":"\u25b6\ufe0f Run the demo","text":"<pre><code>python3 -m modules.ch01_networks.simple_network\n</code></pre> <p>You\u2019ll see outputs interleaved depending on source timing, with both lowercase variants and \u201c!!\u201d variants collected in <code>results</code>.</p>"},{"location":"modules/ch01_networks/README_6/#fan-out-and-fan-in","title":"\ud83e\udde9 Fan-Out and Fan-In","text":"<ul> <li>Fan-Out: Messages from a node can be broadcast to multiple nodes (e.g., <code>from_list_0 \u2192 lower</code> and <code>from_list_0 \u2192 add_bangs</code>).</li> <li>Fan-In: A node can receives messages from multiple nodes (e.g., <code>lower \u2192 to_results</code> and <code>add_bangs \u2192 to_results</code>).</li> </ul>"},{"location":"modules/ch01_networks/README_6/#key-concepts","title":"\ud83e\udde0 Key Concepts","text":"<ul> <li>Arbitrary graphs: You can create networks with arbitrary topologies. (Note: Later we discuss termination detection of networks with cycles. )</li> </ul>"},{"location":"modules/ch01_networks/README_6/#next","title":"\ud83d\udc49 Next","text":"<p>Explore different types of sources.</p>"},{"location":"modules/ch02_sources/README_1/","title":"Module 2 \u2014 Sources","text":""},{"location":"modules/ch02_sources/README_1/#21-sources","title":"\ud83e\udde9 2.1 Sources","text":""},{"location":"modules/ch02_sources/README_1/#goal","title":"\ud83c\udfaf Goal","text":"<ul> <li>Use different types of sources and create your own sources of data.</li> </ul>"},{"location":"modules/ch02_sources/README_1/#whats-a-source","title":"\ud83d\udccd What\u2019s a \u201csource\u201d?","text":"<p>A source is a zero-argument Python callable that yields a stream of values (e.g., a generator). In this module we use standard sources such as RSS news feeds, social media posts, and sensors. Later, we\u2019ll connect sources to AI agents and Python functions to analyze the data. For now, examples focus on source \u2192 display.</p>"},{"location":"modules/ch02_sources/README_1/#connectors","title":"\ud83d\udccd Connectors","text":"<p><code>dsl.connectors</code> contains interfaces to different sources and sinks. We\u2019re actively adding more and welcome contributions.</p> <p>\u26a0\ufe0f Some connectors require registration/API keys or have usage restrictions\u2014even if keys aren\u2019t required. Always review the provider\u2019s terms and docs before using a connector.</p>"},{"location":"modules/ch02_sources/README_1/#examples","title":"\ud83e\udde0 Examples","text":"<ul> <li>RSS sources</li> <li>Social media post sources</li> <li>Coinbase data sources</li> <li>Temperature sensor sources</li> <li>Synthetic data: Sine waves sources</li> </ul>"},{"location":"modules/ch02_sources/README_1/#next","title":"\ud83d\udc49 Next","text":"<p>RSS sources \u2192</p>"},{"location":"modules/ch02_sources/README_2_RSS/","title":"2.2 \u2022 RSS feeds","text":"<p>This page just shows you how to use a connector to an RSS feed. Connectors are described in module 7.</p>"},{"location":"modules/ch02_sources/README_2_RSS/#what-youll-do","title":"What you\u2019ll do","text":"<p>Run a tiny script that reads NASA\u2019s public RSS feed and prints items.</p>"},{"location":"modules/ch02_sources/README_2_RSS/#setup-once","title":"Setup (once)","text":"<pre><code>pip install feedparser requests beautifulsoup4 rich\n</code></pre>"},{"location":"modules/ch02_sources/README_2_RSS/#the-rss-feed-demo","title":"The RSS Feed Demo","text":"<pre><code># modules/ch02_sources/rss_NASA_simple_demo.py\n\nimport time\nfrom dsl import network\nfrom dsl.connectors.rss_in import RSS_In           # &lt;&lt; simplified connector\nfrom .live_kv_console import kv_live_sink             # pretty-print messages live\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# 1) Configure the RSS source (connector)\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Key knobs:\n#   url           \u2013 which RSS/Atom feed to poll (NASA)\n#   fetch_page    \u2013 also fetch the linked article and extract plain text\n#   output_keys   \u2013 keep only these fields from each item/page\n#   poll_seconds  \u2013 how often to check the feed (watchable pace)\n#   life_time     \u2013 how long to run before stopping (seconds)\nrss = RSS_In(\n    url=\"https://www.nasa.gov/feed/\",\n    fetch_page=True,\n    output_keys=[\"title\", \"link\", \"page_text\"],\n    poll_seconds=4,\n    life_time=20,\n)\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# 2) Source function: turn the connector into a generator\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# A source function is a zero-argument callable that yields dicts.\n# We keep only \"title\" and \"page_text\" to keep the console tidy.\n\n\ndef from_rss():\n    for news_item in rss.run():     # iterator of dicts from the connector\n        yield {\n            \"title\": news_item.get(\"title\"),\n            \"page_text\": news_item.get(\"page_text\"),\n        }\n        # Tiny pause so items don't scroll too fast during the demo\n        time.sleep(0.1)\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# 3) Connect source \u2192 sink and run the network\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n\ndef print_sink(msg):\n    print(msg)\n    print(\"-\" * 40)\n\n\ng = network([(from_rss, print_sink)])\n\ng.run_network()\n\n\n\n</code></pre>"},{"location":"modules/ch02_sources/README_2_RSS/#run-the-demo","title":"Run the demo","text":"<pre><code>python3 -m modules.ch02_sources.rss_NASA_simple_demo\n</code></pre> <p>You will see a growing list of items like:</p> <pre><code>----------------------------------------\ntitle\nNASA Updates on [recent story title]\n\nlink\nhttps://www.nasa.gov/...\n\nsummary\nA short blurb from the feed...\n\npage_text\n(First part of the article text, if enabled)\n</code></pre> <p>Newest items appear at the top.</p> <p>If nothing shows immediately, wait a few seconds for the site to be polled and return values.</p>"},{"location":"modules/ch02_sources/README_2_RSS/#parameters-you-can-modify","title":"Parameters you can modify","text":"<ul> <li> <p>poll_seconds: how often to check the feed (e.g., 4 seconds).</p> </li> <li> <p>life_time: how long to run before stopping (e.g., 20 seconds).</p> </li> <li> <p>fetch_page: set to True to also fetch the linked article text.</p> </li> <li> <p>output_keys: choose which fields to print (keep it small for readability).</p> </li> </ul>"},{"location":"modules/ch02_sources/README_2_RSS/#next","title":"\ud83d\udc49 Next","text":"<p>Social Media sources \u2192</p>"},{"location":"modules/ch02_sources/README_3_posts/","title":"2.3 \u2022 Source: Social Media (e.g Bluesky) Feeds","text":"<p>This page just shows you how to use a connector to a social media feed. Connectors are described in module 7.</p>"},{"location":"modules/ch02_sources/README_3_posts/#what-youll-do","title":"What you\u2019ll do","text":"<p>Run a tiny script that listens to the Bluesky Jetstream and prints posts.</p>"},{"location":"modules/ch02_sources/README_3_posts/#setup-once","title":"Setup (once)","text":"<pre><code>pip install websockets rich\n</code></pre>"},{"location":"modules/ch02_sources/README_3_posts/#the-bluesky-feed-demo","title":"The Bluesky Feed Demo","text":"<pre><code># modules.ch02_sources.feed_from_posts\n\nfrom dsl import network\n# dsl.connectors has connectors to different sources of data and sinks\n# including consoles. jetstream_in connects to the Bluesky Jetstream feed.\nfrom dsl.connectors.jetstream_in import Jetstream_In\n# simple sink that prints dicts live\nfrom dsl.connectors.live_kv_console import kv_live_sink\n\n# ----------------------------------------------------\n# 1) Configure the Jetstream source\n# ----------------------------------------------------\n# Key params:\n# - wanted_collections: tuple of Bluesky NSIDs to pass through.\n#     Common examples:\n#       \"app.bsky.feed.post\"   -&gt; posts\n#       \"app.bsky.feed.like\"   -&gt; likes\n# - life_time: stop after N seconds (handy for short demos).\n# - max_num_posts: stop after N posts (safety guard for lessons).\n\njetstream = Jetstream_In(\n    wanted_collections=(\"app.bsky.feed.post\",),  # filter to posts only\n    life_time=20,          # run ~20 seconds then stop (adjust as needed)\n    max_num_posts=25      # or stop after 100 posts, whichever comes first\n)\n\n# ----------------------------------------------------\n# 2) Source function, from_jetstream(), is an iterator\n# ----------------------------------------------------\n# Yields a dict per post.\n\n\ndef from_jetstream():\n    for item in jetstream.run():\n        # item is typically a dict with nested fields.\n        # We trim the dict for the demo.\n        yield {\n            \"uri\": item.get(\"uri\"),\n            \"author\": item.get(\"author_handle\") or item.get(\"author\"),\n            \"text\": item.get(\"text\"),\n            \"created_at\": item.get(\"created_at\"),\n        }\n\n\ndef print_sink(v):\n    print(v)\n    print(\"-\" * 40)\n\n\n# ----------------------------------------------------\n# 3) Connect nodes and run\n# ----------------------------------------------------\ng = network([(from_jetstream, print_sink)])\ng.run_network()\n</code></pre>"},{"location":"modules/ch02_sources/README_3_posts/#run-the-demo","title":"Run the demo","text":"<pre><code>python3 -m modules.ch02_sources.feed_from_posts\n</code></pre> <p>You will see a growing list of items like:</p> <pre><code>----------------------------------------\nauthor\n@alice.bsky.social\n\ntext\nJust launched a new project! \ud83d\ude80\n\nuri\nat://did:plc:.../app.bsky.feed.post/3k2...\n\nindexedAt\n2024-05-12T18:42:03.000Z\n\n</code></pre> <p>Newest items appear at the top.</p> <p>If nothing shows immediately, wait a few seconds for the site to be polled and return values.</p>"},{"location":"modules/ch02_sources/README_3_posts/#parameters-you-can-modify","title":"Parameters you can modify","text":"<ul> <li> <p>poll_seconds: how often to check the feed (e.g., 4 seconds).</p> </li> <li> <p>life_time: how long to run before stopping (e.g., 20 seconds).</p> </li> <li> <p>fetch_page: set to True to also fetch the linked article text.</p> </li> <li> <p>output_keys: choose which fields to print (keep it small for readability).</p> </li> </ul>"},{"location":"modules/ch02_sources/README_3_posts/#next","title":"\ud83d\udc49 Next","text":"<p>Poll from REST sites Poll numeric data from REST \u2192</p>"},{"location":"modules/ch02_sources/README_4_REST/","title":"2.4 \u2022 Source: Polling JSON/REST for Numeric Streams","text":"<p>This page shows how to use a connector that polls a REST/JSON endpoint and turns it into a numeric stream you can process in DisSysLab.  Connectors are described in module 7.</p>"},{"location":"modules/ch02_sources/README_4_REST/#what-youll-do","title":"What you\u2019ll do","text":"<p>Run a tiny script that polls the Coinbase spot-price endpoint ~1\u00d7/sec and prints a record each time the price changes.</p>"},{"location":"modules/ch02_sources/README_4_REST/#setup-once","title":"Setup (once)","text":"<pre><code>pip install requests rich\n</code></pre> <p>Note: We use a public Coinbase endpoint (no API key required) purely as an example. You can swap the URL and extractor for any JSON feed.</p>"},{"location":"modules/ch02_sources/README_4_REST/#the-rest-numeric-feed-demo","title":"The REST \u2192 Numeric Feed Demo","text":"<pre><code># modules.ch02_sources.feed_numeric_price\n\nfrom dsl import network\nfrom dsl.connectors.live_kv_console import kv_live_sink\nfrom dsl.connectors.numeric_rest_in import NumericREST_In\n\n# Coinbase spot price (no API key). Returns JSON like:\n# {\"data\":{\"base\":\"BTC\",\"currency\":\"USD\",\"amount\":\"67890.12\"}}\nURL = \"https://api.coinbase.com/v2/prices/BTC-USD/spot\"\n\n\ndef coinbase_extract_fn(j):\n    data = j.get(\"data\", {})\n    # Convert \"amount\" string -&gt; float; include symbol for clarity.\n    try:\n        price = float(data.get(\"amount\")) if data.get(\"amount\") is not None else None\n    except ValueError:\n        price = None\n    return {\n        \"symbol\": f\"{data.get('base', '?')}-{data.get('currency', '?')}\",\n        \"price\": price,\n        \"note\": \"Coinbase spot (REST)\",\n    }\n\n\nprice_source = NumericREST_In(\n    url=URL,\n    extract_fn=coinbase_extract_fn,\n    poll_seconds=1.0,    # pace you can watch\n    life_time=20.0,      # stop after ~20 s for the demo (None = run forever)\n    dedupe=True,         # emit only on change\n    epsilon=1e-4,        # require \u2265 $0.0001 change to emit a new reading\n)\n\n\ndef from_price():\n    for msg in price_source.run():\n        # Optionally compute derived fields here (e.g., returns, z-scores)\n        yield msg\n\n\n# Wire up the source to a live console sink.\ng = network([(from_price, kv_live_sink)])\n\ng.run_network()\n\nif __name__ == \"__main__\":\n    print(\"finished\")\n</code></pre>"},{"location":"modules/ch02_sources/README_4_REST/#run-the-demo","title":"Run the demo","text":"<pre><code>python3 -m modules.ch02_sources.feed_numeric_price\n</code></pre> <p>You\u2019ll see key\u2013value output like this whenever the price changes:</p> <pre><code>----------------------------------------\nsymbol\nBTC-USD\n\nprice\n67890.12\n\nnote\nCoinbase spot (REST)\n</code></pre>"},{"location":"modules/ch02_sources/README_4_REST/#parameters-you-can-modify","title":"Parameters you can modify","text":"Parameter Type Description url str Any JSON endpoint you\u2019d like to poll. extract_fn callable Maps raw JSON to a dict with at least a numeric field. poll_seconds float How often to poll (e.g., <code>1.0</code>). life_time float | None Max wall-clock duration before auto-stop (<code>None</code> \u2192 run indefinitely). dedupe bool If <code>True</code>, emit only when the numeric value changes. epsilon float Minimum absolute change required to emit (suppresses noise). headers dict (optional) Add HTTP headers if your API requires them. <p>Tip: Your <code>extract_fn</code> can compute and output multiple fields (e.g., <code>{price, pct_change, ts}</code>) for downstream transforms or recorders.</p>"},{"location":"modules/ch02_sources/README_4_REST/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>No output: With <code>dedupe=True</code>, no messages appear until the value changes by at least <code>epsilon</code>.   Temporarily set <code>dedupe=False</code> to confirm polling works.</li> <li>HTTP errors: Check the URL, connectivity, or rate-limit policies. Increase <code>poll_seconds</code> if needed.</li> <li>Non-numeric values: Ensure <code>extract_fn</code> returns a float and handles exceptions defensively.</li> </ul>"},{"location":"modules/ch02_sources/README_4_REST/#next","title":"\ud83d\udc49 Next","text":"<p>Replay archived data  \u2192. See how you can replay saved data to simulate live message streams.</p>"},{"location":"modules/ch02_sources/README_5_replay/","title":"2.5 \u2022 Source - Replay Archived Data Streams","text":"<p>This page shows how to replay rows from a CSV file as a live stream at a specified pace.  Connectors are described in module 7.</p>"},{"location":"modules/ch02_sources/README_5_replay/#what-youll-do","title":"What you\u2019ll do","text":"<p>Run a tiny script that replays temperature data for 2024. This data is in <code>open-meteo_clean.csv</code> which is obtained by extracting the maximum daily temperature from <code>open-meteo-37.79N122.41W18m.csv</code>.</p>"},{"location":"modules/ch02_sources/README_5_replay/#setup-once","title":"Setup (once)","text":"<pre><code>pip install rich\n</code></pre> <p>Note: This example assumes you have <code>open-meteo_clean.csv</code> and <code>ReplayCSV_In</code>. </p>"},{"location":"modules/ch02_sources/README_5_replay/#the-csv-replay-demo","title":"The CSV \u2192 Replay Demo","text":"<pre><code># modules.ch02_sources.feed_numeric_replay\n\nfrom pathlib import Path\nfrom dsl import network\nfrom dsl.connectors.replay_csv_in import ReplayCSV_In\n\nCSV_PATH = str(Path(__file__).resolve().parent / \"open-meteo_clean.csv\")\n\n\ndef transform_row(row):\n    t = row.get(\"time\")\n    temp = row.get(\"temperature_2m_max (\u00b0F)\")\n    if not t or not temp:\n        return None\n    return {\"date\": t, \"max_temp\": float(temp)}\n\n\nreplay = ReplayCSV_In(path=CSV_PATH, transform=transform_row, period_s=0.25)\n\n\ndef print_sink(v):\n    print(v)\n\n\ng = network([(replay.run, print_sink)])\ng.run_network()\n</code></pre>"},{"location":"modules/ch02_sources/README_5_replay/#run-the-demo","title":"Run the demo","text":"<pre><code>python3 -m modules.ch02_sources.feed_numeric_replay\n</code></pre> <p>You\u2019ll see a stream of temperatures.</p>"},{"location":"modules/ch02_sources/README_5_replay/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>No output: Ensure <code>CSV_PATH</code> points to an existing file and your <code>transform_row</code> does not return <code>None</code> for all rows.  </li> <li>Too fast/slow: Adjust <code>period_s</code> to control replay speed.  </li> </ul>"},{"location":"modules/ch02_sources/README_5_replay/#next","title":"\ud83d\udc49 Next","text":"<p>Synthetic data  \u2192. Generate sources from synthetic data for experiments.</p>"},{"location":"modules/ch02_sources/README_6_synthetic/","title":"2.6 \u2022 Synthetic Numeric Source \u2014 Noisy Sum of Sine Waves","text":"<p>This page shows how to generate a synthetic numeric stream as a source in DisSysLab. The signal is a noisy sum of sine waves (e.g., 5 Hz, 12 Hz, 30 Hz plus Gaussian noise), emitted at a fixed sample rate.</p>"},{"location":"modules/ch02_sources/README_6_synthetic/#what-youll-do","title":"What you\u2019ll do","text":"<p>Run a tiny script that produces <code>{\"t\", \"x\"}</code> messages in real time (time in seconds, value as a float) and prints a line every N messages to the console.</p>"},{"location":"modules/ch02_sources/README_6_synthetic/#setup-once","title":"Setup (once)","text":"<pre><code>pip install numpy rich\n</code></pre>"},{"location":"modules/ch02_sources/README_6_synthetic/#the-synthetic-source-demo","title":"The Synthetic Source Demo","text":"<pre><code># modules.ch02_sources.feed_synthetic\n\nfrom dsl import network\n\ndef sine_mixture_source(*, sample_rate=200.0, duration_s=2.0, tones=((5.0, 1.0),), noise_std=0.1):\n    import time\n    import math\n    import numpy as np\n    n_total = int(duration_s * sample_rate)\n    dt = 1.0 / sample_rate\n    t = 0.0\n    tones = list(tones)\n    for _ in range(n_total):\n        x = sum(a * math.sin(2*math.pi*f*t) for f, a in tones) + np.random.normal(scale=noise_std)\n        yield {\"t\": t, \"x\": float(x)}\n        t += dt\n        time.sleep(dt)\n\n# --- sink that prints every N messages so it doesn\u2019t spam ---\ndef make_live_console_sink(every_n=20):\n    i = 0\n    def _sink(msg):\n        nonlocal i\n        i += 1\n        if i % every_n == 0:\n            print(f\"t={msg['t']:6.3f}  x={msg['x']:+8.4f}\")\n        return msg\n    return _sink\n\nlive_console_sink = make_live_console_sink(every_n=20)\n\n# Define and run the network\ng = network([(sine_mixture_source, live_console_sink)])\ng.run_network()\n</code></pre>"},{"location":"modules/ch02_sources/README_6_synthetic/#run-the-demo","title":"Run the demo","text":"<pre><code>python3 -m modules.ch02_sources.feed_synthetic\n</code></pre> <p>You\u2019ll see periodic lines like:</p> <pre><code>t=  0.100  x=  +0.2145\nt=  0.200  x=  -0.5821\nt=  0.300  x=  +0.9473\n...\n</code></pre>"},{"location":"modules/ch02_sources/README_6_synthetic/#parameters-you-can-modify","title":"Parameters you can modify","text":"Parameter Type Description sample_rate float Samples per second (e.g., <code>200.0</code>). Controls pacing (<code>time.sleep(1/sample_rate)</code>). duration_s float Total duration to emit (seconds). tones list[tuple(freq_hz, amplitude)] Sine components that are summed (e.g., <code>((5.0, 1.0), (12.0, 0.6), (30.0, 0.3))</code>). noise_std float Standard deviation of added Gaussian noise. every_n int Console prints every N messages to reduce spam. <p>Note: This source produces a noisy sum of sine waves and is ideal for testing numeric transformers (filters, spectra, anomaly detectors).</p>"},{"location":"modules/ch02_sources/README_6_synthetic/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>No output: Lower <code>every_n</code> (e.g., <code>5</code>) or temporarily print every message.  </li> <li>Runs too fast/slow: Adjust <code>sample_rate</code> (and <code>duration_s</code>).  </li> <li>Choppy timing on some OSes: <code>time.sleep</code> isn\u2019t real-time; it\u2019s fine for demos. Increase <code>every_n</code> to reduce console overhead.</li> </ul>"},{"location":"modules/ch02_sources/README_6_synthetic/#next","title":"\ud83d\udc49 Next","text":"<p>Transformers using AI  \u2192. See how you can use OpenAI and other AI providers to create transformers.</p>"},{"location":"modules/ch03_GPT/README_1/","title":"Module 3 \u2014 OpenAI agents","text":""},{"location":"modules/ch03_GPT/README_1/#31-transformers-that-use-ai","title":"\ud83e\udde9 3.1 Transformers that use AI","text":""},{"location":"modules/ch03_GPT/README_1/#goal","title":"\ud83c\udfaf Goal","text":"<ul> <li>Use transformers using OpenAI agents. See how to build agents using prompts</li> </ul>"},{"location":"modules/ch03_GPT/README_1/#whats-an-ai-transformer","title":"\ud83d\udccd What\u2019s an AI transformer?","text":"<p>A transformer has a single argument and returns a single value. An AI transformer calls an AI agent to compute the return value. In this module we use OpenAI and you can also use other AI providers in the same network.</p> <p>You will need to register with the AI provider and get a key to run these examples and build your own AI agents.</p>"},{"location":"modules/ch03_GPT/README_1/#examples","title":"\ud83e\udde0 Examples","text":"<ul> <li>Analyze sentiment of text</li> <li>Identify entities in text</li> <li>Provide summaries of texts</li> <li>Example of a detailed prompt for weather alerts</li> </ul>"},{"location":"modules/ch03_GPT/README_1/#next","title":"\ud83d\udc49 Next","text":"<p>Analyze sentiment of text</p>"},{"location":"modules/ch03_GPT/README_2_sentiment/","title":"3.2 \u2022 Transformer \u2014 Sentiment Analysis","text":"<p>This page shows how to use AI-based transformers. This example uses OpenAI to score the sentiment of text. You can use AI providers in addition to OpenAI. Other types of transformers are covered in later modules.</p> <p>A transformer function takes one input and returns one value. In this example the function calls an OpenAI agent.</p>"},{"location":"modules/ch03_GPT/README_2_sentiment/#what-youll-do","title":"What you\u2019ll do","text":"<p>Run a tiny script that sends each text to an OpenAI agent which adds a sentiment score in the range \u221210..+10 and gives a short reason.</p>"},{"location":"modules/ch03_GPT/README_2_sentiment/#setup-once","title":"Setup (once)","text":"<pre><code>pip install openai rich\n</code></pre> <p>Set your OpenAI API key (choose one):</p> <p>macOS / Linux</p> <pre><code>export OPENAI_API_KEY=\"sk-\u2026your key\u2026\"\n</code></pre> <p>Windows (PowerShell)</p> <pre><code>$env:OPENAI_API_KEY=\"sk-\u2026your key\u2026\"\n</code></pre> <p>Note: The example uses <code>dsl.extensions.agent_openai.AgentOpenAI</code>, which expects your key in <code>OPENAI_API_KEY</code>.</p>"},{"location":"modules/ch03_GPT/README_2_sentiment/#the-sentiment-demo","title":"The Sentiment Demo","text":"<pre><code># modules.ch03_GPT.sentiment\n\nfrom dsl import network\nfrom dsl.extensions.agent_openai import AgentOpenAI\nimport json\n\n# -----------------------------------------------------------\n# 1) Source \u2014 yield dicts with a \"text\" field\n# -----------------------------------------------------------\n\nlist_of_text = [\n    \"The concert was terrible. I hated the performance.\",\n    \"The book was okay, not too bad but not great either.\",\n    \"This is the best course on AI I've ever taken!\",\n]\n\n\ndef from_list_of_text():\n    for data_item in list_of_text:\n        yield {\"text\": data_item}\n\n# -----------------------------------------------------------\n# 2) OpenAI agent \u2014 provide a system prompt\n# -----------------------------------------------------------\n\n\nsystem_prompt = (\n    \"Determine sentiment score in -10..+10 with -10 most negative, +10 most positive. \"\n    \"Give a brief reason. Return a JSON object with exactly the following format: \"\n    '{\"sentiment_score\": sentiment score, \"reason\": reason for the score}'\n)\nagent = AgentOpenAI(system_prompt=system_prompt)\n\n# -----------------------------------------------------------\n# 3) Transformer \u2014 call the agent and enrich the message\n# -----------------------------------------------------------\n\n\ndef compute_sentiment(msg):\n    # Make a dict from the json str response of the agent\n    sentiment_score_and_reason_json = json.loads(agent.fn(msg[\"text\"]))\n    # enrich the message by adding sentiment_score and reason fields\n    msg.update(sentiment_score_and_reason_json)\n    return msg\n\n# -----------------------------------------------------------\n# 4) Sink \u2014 print values\n# -----------------------------------------------------------\n\n\ndef print_sink(msg):\n    for key, val in msg.items():\n        print(f\"{key}:   {val}\")\n    print(\"--------------------------------\")\n    print()\n\n# -----------------------------------------------------------\n# 5) Connect functions and run network\n# -----------------------------------------------------------\n\n\ng = network([(from_list_of_text, compute_sentiment),\n             (compute_sentiment, print_sink)])\ng.run_network()\n\n</code></pre>"},{"location":"modules/ch03_GPT/README_2_sentiment/#run-the-demo","title":"Run the demo","text":"<pre><code>python -m modules.ch03_openai.sentiment_from_list\n</code></pre> <p>You\u2019ll see output like:</p> <pre><code>{'text': 'The concert was terrible. I hated the performance.',\n 'sentiment': {'score': -8, 'reason': 'Strong negative language'}}\n{'text': 'The book was okay, not too bad but not great either.',\n 'sentiment': {'score': 0, 'reason': 'Mixed, neutral overall'}}\n{'text': \"This is the best course on AI I've ever taken!\",\n 'sentiment': {'score': 9, 'reason': 'Highly positive wording'}}\n</code></pre> <p>(Exact structure/content depends on your AgentOpenAI implementation.)</p>"},{"location":"modules/ch03_GPT/README_2_sentiment/#parameters-you-can-modify","title":"Parameters you can modify","text":"Parameter Type Description list_of_text list[str] The input items to classify. Replace with RSS text, Bluesky posts, etc. system_prompt str Guides the LLM (scoring range, style, and reasoning). add_key str Dict key where the sentiment result is stored (e.g., <code>\"sentiment\"</code>). AgentOpenAI(...) ctor args If supported in your implementation, you can pass model/temperature/max tokens. agent.fn(x) callable The callable that runs the LLM on a single input string. <p>Tip: Keep the system prompt short and specific. If you want just a number, ask for \u201cJSON with {score:int, reason:str}\u201d or just <code>score</code>.</p>"},{"location":"modules/ch03_GPT/README_2_sentiment/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Auth errors: Ensure <code>OPENAI_API_KEY</code> is set in the environment seen by the Python process.  </li> <li>Rate limits / timeouts: Add basic retry/backoff in <code>AgentOpenAI</code> or slow the input source.  </li> <li>Unexpected output format: Tighten the prompt (e.g., \u201cReturn JSON with keys <code>score</code> and <code>reason</code> only.\u201d).  </li> <li>Cost control: Use small batches or shorter inputs; consider cheaper models if your Agent supports a model override.</li> </ul>"},{"location":"modules/ch03_GPT/README_2_sentiment/#next-steps","title":"Next steps","text":"<ul> <li>Swap the source to RSS or Jetstream text and keep the same <code>agent_op</code> transformer.  </li> <li>Create a keyword filter transformer before the LLM call to reduce cost.  </li> <li>Record results to JSONL and plot sentiment over time (Module 5 + later examples).  </li> <li>Try summarization or entity extraction with a similar <code>AgentOpenAI</code> wrapper.</li> </ul>"},{"location":"modules/ch03_GPT/README_3_entity/","title":"3.2 \u2022 Transformer \u2014 Entity Extraction","text":"<p>This page shows how to use transformers using OpenAI to extract entities -- people, places, organizations -- from text.</p>"},{"location":"modules/ch03_GPT/README_3_entity/#what-youll-do","title":"What you\u2019ll do","text":"<p>Run a tiny script that sends each text to an OpenAI agent and adds an <code>entities</code> field to each dict with the extracted entities.</p>"},{"location":"modules/ch03_GPT/README_3_entity/#setup-once","title":"Setup (once)","text":"<pre><code>pip install openai rich\n</code></pre> <p>Set your OpenAI API key (choose one):</p> <p>macOS / Linux</p> <pre><code>export OPENAI_API_KEY=\"sk-\u2026your key\u2026\"\n</code></pre> <p>Windows (PowerShell)</p> <pre><code>$env:OPENAI_API_KEY=\"sk-\u2026your key\u2026\"\n</code></pre> <p>Note: The example uses <code>dsl.extensions.agent_openai.AgentOpenAI</code>, which expects your key in <code>OPENAI_API_KEY</code>.</p>"},{"location":"modules/ch03_GPT/README_3_entity/#the-entity-extraction-demo","title":"The Entity Extraction Demo","text":"<pre><code># modules.ch03_GPT.entities_from_list\n\nfrom dsl import network\nfrom dsl.extensions.agent_openai import AgentOpenAI\nimport json\n\n# -----------------------------------------------------------\n# 1) Source \u2014 yield dicts with a \"text\" field\n# -----------------------------------------------------------\n\nlist_of_text = [\n    \"Obama was the first African American president of the USA.\",\n    \"The capital of India is New Delhi and its Prime Minister is Narendra Modi.\",\n    \"BRICS is an organization of Brazil, Russia, India, China and South Africa. Putin, Xi, and Modi met in Beijing\",\n]\n\n\ndef from_list_of_text():\n    for data_item in list_of_text:\n        yield {\"text\": data_item}\n\n# -----------------------------------------------------------\n# 2) OpenAI agent \u2014 provide a system prompt\n# -----------------------------------------------------------\n\n\nsystem_prompt = (\n    \"Your task is to read the input text and extract entities\"\n    \"such as names of people, organizations, countries and locations.\"\n    \"Return a JSON array of the entities found in the text where the key is\"\n    \" the type of entity (e.g., Person, Organization, Location) and the value\"\n    \"is the list of entities of that type. For example\"\n    '{\"Person\": [\"Obama\", \"Modi\"], \"Location\": [\"USA\", \"New Delhi\"]}'\n)\nagent = AgentOpenAI(system_prompt=system_prompt)\n\n# ---------------------------------------------------------------------\n# 3) Transformer \u2014 call the agent, add enrich the message with entities\n# ----------------------------------------------------------------------\n\n\ndef add_entities_to_msg(msg):\n    # Make a dict from the json str response of the agent\n    entities = json.loads(agent.fn(msg[\"text\"]))\n    # enrich the message by adding sentiment_score and reason fields\n    msg.update(entities)\n    return msg\n\n\n# -----------------------------------------------------------\n# 4) Sink \u2014 pretty print dict keys/values\n# -----------------------------------------------------------\n\n\ndef print_sink(v):\n    print(\"==============================\")\n    for key, value in v.items():\n        print(key)\n        print(value)\n        print(\"______________________________\")\n    print(\"\")\n\n# -----------------------------------------------------------\n# 5) Connect functions and run\n# -----------------------------------------------------------\n\n\ng = network([(from_list_of_text, add_entities_to_msg),\n             (add_entities_to_msg, print_sink)])\ng.run_network()\n\n\n</code></pre>"},{"location":"modules/ch03_GPT/README_3_entity/#run-the-demo","title":"Run the demo","text":"<pre><code>python3 -m modules.ch03_openai.entities_from_list\n</code></pre> <p>You\u2019ll see output like (shape depends on your <code>AgentOpenAI</code> implementation and prompt):</p> <pre><code>==============================\ntext\nObama was the first African American president of the USA.\n______________________________\nentities\nEntities extracted:\n- Obama (Person)\n- African American (Ethnicity)\n- USA (Country)\n______________________________\n\n\n</code></pre>"},{"location":"modules/ch03_GPT/README_3_entity/#parameters-you-can-modify","title":"Parameters you can modify","text":"Parameter Type Description list_of_text list[str] The input items to process. Replace with RSS text, Bluesky posts, etc. system_prompt str Guides the LLM about what to extract and the output format. agent_op callable The transformer that invokes the LLM and writes to <code>entities</code>. AgentOpenAI(...) ctor args If supported, pass model/temperature/max tokens to control cost/latency. agent.fn(x) callable The callable that runs the LLM for a single input string. <p>Tip: For consistent downstream processing, make the prompt request a strict JSON schema, e.g.: \u201cReturn JSON: <code>{\"entities\":[{\"type\":\"PERSON\",\"name\":\"...\"}, ...]}</code>. No text outside JSON.\u201d</p>"},{"location":"modules/ch03_GPT/README_3_entity/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Auth errors: Ensure <code>OPENAI_API_KEY</code> is set in the environment seen by the Python process.  </li> <li>Unexpected output format: Tighten the system prompt to require strict JSON with fixed keys.  </li> <li>Long/slow responses: Reduce input length, switch to a cheaper/faster model, or add batching/rate limiting.  </li> <li>Privacy: Avoid sending sensitive or personally identifiable text to external APIs without consent.</li> </ul>"},{"location":"modules/ch03_GPT/README_3_entity/#next-steps","title":"Next steps","text":"<ul> <li>Swap the source to RSS or Jetstream to extract entities from live feeds.  </li> <li>Chain a transformer to count entities by type or name and compute frequencies.  </li> <li>Record results to JSONL for later analysis (Module 5), or visualize top entities.  </li> <li>Try a hybrid prompt that extracts both entities and sentiment per entity.</li> </ul>"},{"location":"modules/ch03_GPT/README_4_summarizer/","title":"3.4 \u2022 Transformer \u2014 Summarize Text","text":"<p>This page shows how to use a transformer using OpenAI to summarize text.</p>"},{"location":"modules/ch03_GPT/README_4_summarizer/#what-youll-do","title":"What you\u2019ll do","text":"<p>Run a tiny script that sends each text to an OpenAI agent and adds a one-line summary to the message dict.</p>"},{"location":"modules/ch03_GPT/README_4_summarizer/#setup-once","title":"Setup (once)","text":"<pre><code>pip install openai rich\n</code></pre> <p>Set your OpenAI API key (choose one):</p> <p>macOS / Linux</p> <pre><code>export OPENAI_API_KEY=\"sk-\u2026your key\u2026\"\n</code></pre> <p>Windows (PowerShell)</p> <pre><code>$env:OPENAI_API_KEY=\"sk-\u2026your key\u2026\"\n</code></pre> <p>Note: This example uses <code>dsl.extensions.agent_openai.AgentOpenAI</code>, which looks for <code>OPENAI_API_KEY</code>.</p>"},{"location":"modules/ch03_GPT/README_4_summarizer/#the-summarization-demo","title":"The Summarization Demo","text":"<pre><code># modules.ch03_GPT.summary_from_list\n\nfrom dsl import network\nfrom dsl.extensions.agent_openai import AgentOpenAI\n\n# -----------------------------------------------------------\n# 1) Source \u2014 yield dicts with a \"text\" field\n# -----------------------------------------------------------\n\nlist_of_text = [\n    (\n        \"A play is a form of theatre that primarily consists of\"\n        \" script between speakers and is intended for acting rather\"\n        \" than mere reading. The writer and author of a play is\"\n        \" known as a playwright. Plays are staged at various levels,\"\n        \" ranging from London's West End and New York City's\"\n        \" Broadway \u2013 the highest echelons of commercial theatre in\"\n        \" the English-speaking world \u2013 to regional theatre, community\"\n        \" theatre, and academic productions at universities and schools.\"\n    )\n]\n\ndef from_list_of_text():\n    for data_item in list_of_text:\n        yield {\"text\": data_item}\n\n# -----------------------------------------------------------\n# 2) OpenAI agent \u2014 provide a system prompt\n# -----------------------------------------------------------\n\nsystem_prompt = \"Summarize the text in a single line.\"\nagent = AgentOpenAI(system_prompt=system_prompt)\n\n# -----------------------------------------------------------\n# 3) Transformer \u2014 call the agent, add result under add_key\n# -----------------------------------------------------------\n\ndef agent_op(v):\n    v[\"summary\"] = agent.fn(v[\"text\"])\n    return v\n\n# -----------------------------------------------------------\n# 4) Sink \u2014 collect results (or print/log)\n# -----------------------------------------------------------\n\nresults = []\ndef to_results(v):\n    results.append(v)\n\n# -----------------------------------------------------------\n# 5) Wire and run\n# -----------------------------------------------------------\n\ng = network([(from_list_of_text, agent_op), (agent_op, to_results)])\ng.run_network()\n\nif __name__ == \"__main__\":\n    for result in results:\n        for key, value in result.items():\n            print(key)\n            print(value)\n        print(\"\")\n</code></pre>"},{"location":"modules/ch03_GPT/README_4_summarizer/#run-the-demo","title":"Run the demo","text":"<pre><code>python3 -m modules.ch03_openai.summary_from_list\n</code></pre> <p>You\u2019ll see output containing the original <code>text</code> and a one-line <code>summary</code>, for example:</p> <pre><code>text\nA play is a form of theatre that primarily consists of script \u2026\n\nsummary\nA play is a theatrical work written by a playwright and intended for performance, staged from major commercial venues to community and academic productions.\n</code></pre>"},{"location":"modules/ch03_GPT/README_4_summarizer/#parameters-you-can-modify","title":"Parameters you can modify","text":"Parameter Type Description list_of_text list[str] Replace with your own texts (e.g., RSS article bodies). system_prompt str Controls style/length (e.g., \u201cbullet list,\u201d \u201cmax 20 words,\u201d \u201cinclude keywords\u201d). add_key str Dict key where the summary is stored (default <code>\"summary\"</code>). AgentOpenAI(...) ctor args If supported, override model/temperature/max tokens. agent.fn(x) callable The callable that runs the LLM for a single string input. <p>Tip: To ensure consistent formatting, ask for strict JSON: \u201cReturn JSON <code>{ \"summary\": \"&lt;one line&gt;\" }</code> with no extra text.\u201d</p>"},{"location":"modules/ch03_GPT/README_4_summarizer/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Auth errors: Ensure <code>OPENAI_API_KEY</code> is available in your shell/environment.  </li> <li>Very long outputs: Tighten the prompt (e.g., \u201c\u2264 20 words\u201d), reduce input length, or change model params.  </li> <li>Latency / cost: Batch fewer items, trim text, or switch to a faster/cheaper model if supported.</li> </ul>"},{"location":"modules/ch03_GPT/README_4_summarizer/#next-steps","title":"Next steps","text":"<ul> <li>Chain with entity extraction or sentiment to build richer annotations.  </li> <li>Record results to JSONL/CSV (Module 5) and evaluate summary quality over time.  </li> <li>Add a pre-transform to truncate or clean inputs (strip boilerplate, HTML).</li> </ul>"},{"location":"modules/ch03_GPT/README_5_WeatherAlerts/","title":"5 \u2022 Transformers: Weather Alerts","text":"<p>Important notes 1) Do not use the weather alerts feed casually. This is an operational feed intended for real, potentially life-threatening alerts. Use it respectfully and only for learning/testing as needed. 2) The weather alerts feed can be slow to respond. You may need to wait several minutes before seeing output.</p> <p>This page shows how to connect to the NWS Weather Alerts (Atom/RSS) feed and run an OpenAI transformer to extract a compact, safety-focused summary from each alert.</p>"},{"location":"modules/ch03_GPT/README_5_WeatherAlerts/#what-youll-do","title":"What you\u2019ll do","text":"<p>Run a script that polls the official NWS active alerts feed, extracts a small dict per alert (<code>title</code>, <code>page_text</code>), and sends it to an OpenAI agent that returns a minimal JSON summary (<code>alert_type</code>, <code>location</code>, <code>issued_time</code>, <code>headline</code>, <code>short_advice</code>). The output is streamed to a live console sink.</p>"},{"location":"modules/ch03_GPT/README_5_WeatherAlerts/#setup-once","title":"Setup (once)","text":"<pre><code>pip install requests beautifulsoup4 lxml openai rich\n</code></pre> <p>Set your OpenAI API key (choose one):</p> <p>macOS / Linux</p> <pre><code>export OPENAI_API_KEY=\"sk-\u2026your key\u2026\"\n</code></pre> <p>Windows (PowerShell)</p> <pre><code>$env:OPENAI_API_KEY=\"sk-\u2026your key\u2026\"\n</code></pre> <p>Notes: \u2022 <code>lxml</code> enables reliable XML parsing for Atom/RSS feeds. \u2022 The example uses <code>dsl.extensions.agent_openai.AgentOpenAI</code>, which expects your key in <code>OPENAI_API_KEY</code>.</p>"},{"location":"modules/ch03_GPT/README_5_WeatherAlerts/#the-weather-alerts-demo","title":"The Weather Alerts Demo","text":"<pre><code># modules.ch03_GPT.rss_alerts_demo\n\nfrom dsl.connectors.rss_in import RSS_In\nfrom dsl import network\nfrom dsl.extensions.agent_openai import AgentOpenAI\nfrom .live_alert_console import live_alert_sink\n\n# Define functions.\nrss = RSS_In(\n    url=\"https://api.weather.gov/alerts/active.atom/\",\n    fetch_page=True,\n    poll_seconds=4,\n    life_time=20,\n)\n\ndef from_rss():\n    news_items = rss.run()\n    for news_item in news_items:\n        print(f\"news_item = {news_item}\")\n        yield {k: news_item.get(k) for k in (\"title\", \"page_text\")}\n\nsystem_prompt = '''You are a weather-alert extraction agent. \nYour job is to analyze an alert which is a dict {'title': title, 'page_text': 'page_text} where title is a short\nstring and page_text is a long string.\nYour job is to extract information from the alert and return a JSON object \nwith exactly the following keys:\n\n\"alert_type\" \u2014 the official alert name (e.g., Small Craft Advisory, Flood Watch).\n\n\"location\" \u2014 the human-readable city and state/territory code (e.g., Anchorage AK, Melbourne FL). \nPrefer the phrase after \u201cby NWS \u2026\u201d in the title (e.g., \u201cby NWS Anchorage AK\u201d \u2192 Anchorage AK). If that isn\u2019t present, use the clearest city+state mentioned in the alert text. If truly unknown, use null.\n\n\"issued_time\" \u2014 the alert issuance time in UTC ISO-8601 (YYYY-MM-DDThh:mm:ssZ).\n\nIf not explicitly provided, use the most plausible end/expiration time implied by the alert; if truly unknown, use null.\n\n\"headline\" \u2014 a short, natural-language headline summarizing the alert and timeframe (e.g., Small Craft Advisory until Saturday evening). Keep it under ~80 characters.\n\n\"short_advice\" \u2014 one concise, practical safety tip tailored to the alert (less than 40 words, imperative mood, no exclamation marks).\n\nOutput requirements:\n\nReturn exactly one JSON object with only these five keys, in this order.\n\nAll values must be strings, except you may use null for unknown times or location.\n\nNormalize all times to UTC with a Z suffix. Convert from offsets in the input (e.g., \u2026-08:00 \u2192 add 8 hours).\n\nDo not include explanations, reasoning, markdown, or extra fields.\n\nExtraction guidance (apply in this priority):\n\nalert_type: take the segment before \u201cissued \u2026\u201d in the title; if absent, use the named event in the text (e.g., NWSheadline, event).\n\nlocation: prefer the substring after by NWS at the end of the title (e.g., by NWS Anchorage AK \u2192 Anchorage AK). If multiple places are listed, pick the primary office/city associated with the NWS office. If only county/zone codes are present, choose the principal city referenced; otherwise null.\n\nTimes:\n\nParse all RFC 822/ISO-8601 timestamps in the title/text.\n\nIssued: the timestamp closest to the word \u201cissued\u201d in the title; if not present, the earliest timestamp in the text.\n\nheadline: &lt;Alert Type&gt; \u2026 + concise timeframe (e.g., \u201cuntil Saturday evening\u201d, \u201cthrough Sunday morning\u201d).\n\nshort_advice: write one or two actionable sentences appropriate to the hazard (e.g., marine \u2192 \u201cDelay small-vessel trips and check latest marine forecast.\u201d; flood \u2192 \u201cAvoid flooded roads; monitor updates and be ready to seek higher ground.\u201d).\n\nReturn format example (illustrative only):\n{\n\"alert_type\": \"Small Craft Advisory\",\n\"location\": \"Anchorage AK\",\n\"issued_time\": \"2025-10-03T11:31:00Z\",\n\"headline\": \"Small Craft Advisory until Saturday evening\",\n\"short_advice\": \"Delay small-vessel trips and check the latest marine forecast before departing.\"\n}\nOutput rules:\n- Return ONLY valid RFC8259 JSON. No markdown, no code fences, no comments, no extra text.\n- Use double quotes for all keys and strings.\n- No trailing commas.\n- If none found, use [] (empty array).\n- Begin the response with \"{\" and end with \"}\".\n'''\nagent = AgentOpenAI(system_prompt=system_prompt)\n\ndef print_sink(v):\n    print(v)\n\n# Define the network\ng = network([(from_rss, agent.fn), (agent.fn, live_alert_sink)])\ng.run_network()\n</code></pre>"},{"location":"modules/ch03_GPT/README_5_WeatherAlerts/#run-the-demo","title":"Run the demo","text":"<pre><code>python3 -m examples.rss_alerts_demo\n</code></pre> <p>You should see alert summaries printed in the live console (after a possible delay).  </p> <p></p>"},{"location":"modules/ch03_GPT/README_5_WeatherAlerts/#parameters-you-can-modify","title":"Parameters you can modify","text":"Parameter Type Description url str The Atom/RSS feed URL (defaults to active NWS alerts). fetch_page bool If <code>True</code>, fetch and parse the linked alert page for richer <code>page_text</code>. poll_seconds float How often to repoll for new alerts. Increase to be kinder to servers. life_time float | None Max wall-clock duration before auto-stop (<code>None</code> \u2192 run indefinitely). system_prompt str Controls the exact extraction schema and normalization rules. live_alert_sink sink Console sink for live, readable output (replace with a file/JSONL sink if desired). <p>Tip: If your <code>rss_in</code> supports XML parsing options, prefer an XML parser (e.g., <code>lxml-xml</code>) for Atom/RSS feeds to avoid HTML-as-XML warnings.</p>"},{"location":"modules/ch03_GPT/README_5_WeatherAlerts/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Long delay / no output: The active alerts feed can be slow and may have lulls; wait several minutes. You can also extend <code>life_time</code>.  </li> <li>XMLParsedAsHTMLWarning: Install <code>lxml</code> and parse feeds as XML (<code>\"lxml-xml\"</code>); keep <code>\"html.parser\"</code> for fetched article pages only.  </li> <li>Rate limiting / HTTP errors: Increase <code>poll_seconds</code>, check connectivity, and avoid aggressive polling.  </li> <li>Unexpected model output: Tighten the <code>system_prompt</code> to require strict JSON with exactly the five keys, no extra text.  </li> <li>Time normalization: If UTC conversion seems off, explicitly instruct the model to normalize to <code>Z</code> and double-check the source timestamps.</li> </ul>"},{"location":"modules/ch03_GPT/README_5_WeatherAlerts/#next-steps","title":"Next steps","text":"<ul> <li>Swap the sink for a JSONL/CSV recorder (Module 5) to log alerts for later analysis.  </li> <li>Add a transform to filter by alert type or location (e.g., marine only, a specific state).  </li> <li>Combine with other sources (Module 2) to build a situational awareness dashboard.  </li> <li>Extend the prompt to extract severity, areas, or expiration when present.</li> </ul>"},{"location":"modules/ch04_numeric/README_2_anomaly/","title":"4.2 \u2022 Transform - Numerics detect Anomalies","text":"<p>This page gives you an example of a simple numeric transform using sliding windows.</p>"},{"location":"modules/ch04_numeric/README_2_anomaly/#what-youll-do","title":"What you\u2019ll do","text":"<p>Run a tiny script that replays temperatures recorded for San Francisco, emits each row at ~4\u00d7/sec, computes statistics over sliding windows, and uses these statistics to predict future temperatures and identify anomalies in the temperature stream. The results are displayed on the console.</p>"},{"location":"modules/ch04_numeric/README_2_anomaly/#setup-once","title":"Setup (once)","text":"<pre><code>pip install rich\n</code></pre> <p>Note: This example assumes you have <code>open-meteo_clean.csv</code>, <code>ReplayCSV_In</code>, <code>rolling_stats_anom_forecast</code>, and a <code>temp_live_sink</code> available in your project paths as shown below.</p>"},{"location":"modules/ch04_numeric/README_2_anomaly/#a-numeric-transformer","title":"A numeric transformer","text":"<pre><code># modules.ch04_numeric.simple_anomaly\n\nfrom pathlib import Path\nfrom dsl import network\nfrom dsl.connectors.replay_csv_in import ReplayCSV_In\nfrom .rolling_stats_anom_forecast import rolling_stats_anom_forecast\nfrom .temp_live_sink import temp_live_sink\n\n# -------------------------------------------------------------------------\n# Source: Generate historical daily max temperature from Open-Meteo\nCSV_PATH = str(Path(__file__).resolve().parent / \"open-meteo_clean.csv\")\n\n\ndef transform_row(row):\n    t = row.get(\"time\")\n    temp = row.get(\"temperature_2m_max (\u00b0F)\")\n    if not t or not temp:\n        return None\n    return {\"date\": t, \"tmax_f\": float(temp)}\n\n\nreplay = ReplayCSV_In(path=CSV_PATH, transform=transform_row, period_s=0.25)\n\n\n# -------------------------------------------------------------------------\n# Transform: Rolling statistics for anomaly detection and forecasting\nxf = rolling_stats_anom_forecast(\n    window=20,\n    k_anom=2.0,      # anomaly threshold\n    k_pred=0.5,      # prediction band width\n    key_in=\"tmax_f\",\n    date_key=\"date\",\n    prefix=\"w20\"\n)\n\n# -------------------------------------------------------------------------\n# Sink: Use temp_live_sink to display results\n\n# -------------------------------------------------------------------------\n# Network: Connect functions\n\ng = network([(replay.run, xf), (xf, temp_live_sink)])\ng.run_network()\n</code></pre>"},{"location":"modules/ch04_numeric/README_2_anomaly/#run-the-demo","title":"Run the demo","text":"<pre><code>python3 -m modules.ch04_numeric.simple_anomaly\n</code></pre> <p>You\u2019ll see a live stream of key\u2013value output with rolling statistics, anomaly flags, and prediction band fields.</p>"},{"location":"modules/ch04_numeric/README_2_anomaly/#parameters-you-can-modify","title":"Parameters you can modify","text":"Parameter Type Description path str Path to the CSV file to replay. transform callable | None Maps a CSV row (dict) \u2192 cleaned dict (return <code>None</code> to skip a row). period_s float Seconds between emitted rows (e.g., <code>0.25</code> \u2248 4 msgs/sec). window int Rolling window length for stats (e.g., <code>20</code>). k_anom float Anomaly threshold multiplier (e.g., <code>2.0</code>). k_pred float Prediction band half-width multiplier (e.g., <code>0.5</code>). key_in str Input numeric field name (e.g., <code>\"tmax_f\"</code>). date_key str Timestamp/date field name (e.g., <code>\"date\"</code>). prefix str Prefix for derived fields (e.g., <code>\"w20\"</code> \u2192 <code>w20_mean</code>, <code>w20_lo</code>, <code>w20_hi</code>, etc.). <p>Tip: Customize <code>transform_row</code> to rename columns and cast types up front so downstream transformers can operate on a predictable schema.</p>"},{"location":"modules/ch04_numeric/README_2_anomaly/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>No output: Ensure <code>CSV_PATH</code> points to an existing file and your <code>transform_row</code> does not return <code>None</code> for all rows.  </li> <li>Type errors: Cast numbers in <code>transform_row</code> (e.g., <code>float(temp)</code>) and verify column names match the CSV header.  </li> <li>Too fast/slow: Adjust <code>period_s</code> to control replay speed.  </li> <li>Missing fields in sink: Confirm your sink expects the fields your pipeline emits (e.g., <code>date</code>, <code>tmax_f</code>, <code>w20_*</code>).  </li> </ul>"},{"location":"modules/ch04_numeric/README_2_anomaly/#next-steps","title":"Next steps","text":"<ul> <li>Replace <code>temp_live_sink</code> with a JSONL/CSV recorder to log outputs (Module 2.5 / Module 5).  </li> <li>Chain a keyword/threshold filter before the sink to highlight anomalies.  </li> <li>Plot the replayed series and prediction bands in a notebook or dashboard.</li> </ul>"},{"location":"modules/ch04_numeric/README_3_filter/","title":"4.1 \u2022 Numeric Transformers \u2014 Synthetic Sine Mixture (Library Functions as Nodes)","text":"<p>This demo shows how plain Python functions that call existing libraries (NumPy/SciPy) can act as nodes in a DisSysLab network. We synthesize a sum of noisy sine waves, then run two transforms: 1) a Butterworth band-pass filter (SciPy), and 2) a spectrum/peak detector (Welch PSD + peak pick, SciPy), and finally save a spectrum snapshot (PNG) for your README/slides.</p>"},{"location":"modules/ch04_numeric/README_3_filter/#what-youll-do","title":"What you\u2019ll do","text":"<ul> <li>Generate a live stream: <code>x(t) = \u03a3 A_k sin(2\u03c0 f_k t) + noise</code>.  </li> <li>Transform 1: Isolate a target band with <code>scipy.signal.butter</code> + <code>sosfilt</code>.  </li> <li>Transform 2: Estimate the spectrum via <code>scipy.signal.welch</code> and find dominant frequency peaks via <code>scipy.signal.find_peaks</code>.  </li> <li>Sink: Save <code>spectrum.png</code> once enough data has accumulated (no live plotting required).</li> </ul>"},{"location":"modules/ch04_numeric/README_3_filter/#setup-once","title":"Setup (once)","text":"<pre><code>pip install numpy scipy matplotlib rich\n</code></pre>"},{"location":"modules/ch04_numeric/README_3_filter/#the-synthetic-sine-mixture-demo","title":"The Synthetic Sine Mixture Demo","text":"<pre><code># modules.ch04_numeric.synthetic_sines_demo\n\nimport time\nimport math\nfrom collections import deque\nfrom typing import Iterable, Dict, Any, Tuple\n\nimport numpy as np\nfrom scipy.signal import butter, sosfilt, welch, find_peaks\nimport matplotlib.pyplot as plt\n\nfrom dsl import network\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# 1) Source \u2014 sum of noisy sines (yields {\"t\", \"x\"})\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ndef sine_mixture_source(\n    *,\n    sample_rate: float = 200.0,\n    duration_s: float = 8.0,\n    tones: Iterable[Tuple[float, float]] = ((5.0, 1.0), (12.0, 0.6), (30.0, 0.3)),  # (freq_hz, amplitude)\n    noise_std: float = 0.15,\n):\n    n_total = int(duration_s * sample_rate)\n    dt = 1.0 / sample_rate\n    t = 0.0\n    tones = list(tones)\n    for _ in range(n_total):\n        x = 0.0\n        for f, a in tones:\n            x += a * math.sin(2 * math.pi * f * t)\n        x += np.random.normal(scale=noise_std)\n        yield {\"t\": t, \"x\": float(x)}\n        t += dt\n        time.sleep(dt)  # real-time pacing\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# 2) Transform A \u2014 Butterworth band-pass (SciPy)\n#    Adds \"x_bp\" to each message\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ndef butter_bandpass_transform(\n    *,\n    low_hz: float = 4.0,\n    high_hz: float = 14.0,\n    order: int = 4,\n    sample_rate: float = 200.0,\n    key_in: str = \"x\",\n    key_out: str = \"x_bp\",\n):\n    nyq = 0.5 * sample_rate\n    low = low_hz / nyq\n    high = high_hz / nyq\n    sos = butter(order, [low, high], btype=\"bandpass\", output=\"sos\")\n    def _transform(msg: Dict[str, Any]) -&gt; Dict[str, Any]:\n        x = float(msg[key_in])\n        y = float(sosfilt(sos, [x])[-1])  # one-sample step\n        msg[key_out] = y\n        return msg\n    return _transform\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# 3) Transform B \u2014 Welch PSD + peak pick (SciPy)\n#    Adds: \"f0_hz\" (top peak), \"peaks_hz\" (list), and exposes \"freqs\"/\"psd\"\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ndef welch_peak_detector(\n    *,\n    window_samples: int = 1024,\n    sample_rate: float = 200.0,\n    key_in: str = \"x_bp\",          # detect on band-passed signal\n    key_out_freq: str = \"f0_hz\",\n    key_out_peaks: str = \"peaks_hz\",\n    min_prominence: float = 0.02\n):\n    buf = deque(maxlen=window_samples)\n    def _transform(msg: Dict[str, Any]) -&gt; Dict[str, Any]:\n        x = float(msg[key_in])\n        buf.append(x)\n        if len(buf) == window_samples:\n            arr = np.asarray(buf, dtype=np.float32)\n            freqs, psd = welch(arr, fs=sample_rate, nperseg=min(256, window_samples))\n            # expose arrays for the snapshot sink\n            msg[\"freqs\"] = freqs.tolist()\n            msg[\"psd\"] = psd.tolist()\n            peaks, props = find_peaks(psd, prominence=min_prominence)\n            if peaks.size &gt; 0:\n                order = np.argsort(psd[peaks])[::-1]\n                main = peaks[order[0]]\n                msg[key_out_freq] = float(freqs[main])\n                msg[key_out_peaks] = [float(freqs[p]) for p in peaks[order[:5]]]\n            else:\n                msg[key_out_freq] = None\n                msg[key_out_peaks] = []\n        else:\n            msg[key_out_freq] = None\n            msg[key_out_peaks] = []\n            msg[\"freqs\"] = None\n            msg[\"psd\"] = None\n        return msg\n    return _transform\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# 4) Sink \u2014 save a spectrum snapshot (PNG) at the end\n#    Call sink.finalize() after g.run_network()\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ndef snapshot_spectrum_sink(filename=\"spectrum.png\", key_freqs=\"freqs\", key_psd=\"psd\"):\n    latest = {\"freqs\": None, \"psd\": None}\n    def _sink(msg: Dict[str, Any]):\n        f = msg.get(key_freqs); Pxx = msg.get(key_psd)\n        if f is not None and Pxx is not None:\n            latest[\"freqs\"] = np.asarray(f)\n            latest[\"psd\"] = np.asarray(Pxx)\n        return msg\n    def _finalize():\n        f, Pxx = latest[\"freqs\"], latest[\"psd\"]\n        if f is None or Pxx is None:\n            print(\"[snapshot] No PSD captured; nothing to save.\")\n            return\n        plt.figure()\n        plt.semilogy(f, Pxx)\n        plt.xlabel(\"Frequency (Hz)\"); plt.ylabel(\"Power spectral density\")\n        plt.title(\"Welch PSD snapshot\")\n        plt.tight_layout()\n        plt.savefig(filename, dpi=150)\n        print(f\"[snapshot] Saved {filename}\")\n    _sink.finalize = _finalize\n    return _sink\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# 5) (Optional) Console sink for quick feedback\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ndef live_console_sink(msg: Dict[str, Any]):\n    t = msg[\"t\"]\n    f0 = msg.get(\"f0_hz\")\n    if int(t * 10) == t * 10:  # ~10 Hz logging\n        print(f\"t={t:5.2f}  f0={('None' if f0 is None else f'{f0:6.2f} Hz')}\")\n    return msg\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# 6) Wire the graph \u2014 library functions as nodes\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\nsrc = sine_mixture_source(sample_rate=200.0, duration_s=8.0,\n                          tones=((5.0, 1.0), (12.0, 0.6), (30.0, 0.3)),\n                          noise_std=0.15)\n\nbp  = butter_bandpass_transform(low_hz=4.0, high_hz=14.0, order=4, sample_rate=200.0, key_in=\"x\", key_out=\"x_bp\")\ndet = welch_peak_detector(window_samples=1024, sample_rate=200.0, key_in=\"x_bp\", min_prominence=0.02)\n\nsnap = snapshot_spectrum_sink(\"spectrum.png\")\n\ng = network([\n    (src, bp),           # Transform 1: band-pass\n    (bp, det),           # Transform 2: Welch + peaks\n    (det, live_console_sink),  # optional console\n    (det, snap),         # PNG snapshot sink\n])\n\ng.run_network()\nif hasattr(snap, \"finalize\"): snap.finalize()\n</code></pre>"},{"location":"modules/ch04_numeric/README_3_filter/#run-the-demo","title":"Run the demo","text":"<pre><code>python3 -m modules.ch04_numeric.synthetic_sines_demo\n</code></pre> <p>You\u2019ll see console lines (after the buffer fills) and a saved <code>spectrum.png</code>.</p>"},{"location":"modules/ch04_numeric/README_3_filter/#parameters-you-can-modify","title":"Parameters you can modify","text":"Parameter Where Description sample_rate source/transforms Keep consistent (e.g., <code>200.0</code>). tones source List of <code>(freq_hz, amplitude)</code> pairs. noise_std source Gaussian noise level. low_hz / high_hz / order band-pass Butterworth passband and order. window_samples detector Rolling buffer for Welch PSD. min_prominence detector Peak detection sensitivity."},{"location":"modules/ch04_numeric/README_3_filter/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>No PNG saved: Ensure the detector emitted <code>freqs</code>/<code>psd</code> (wait until the buffer fills or lower <code>window_samples</code>).  </li> <li>No peaks detected: Lower <code>min_prominence</code>, increase tone amplitudes, or reduce noise.  </li> <li>Peaks off by ~\u0394f: Increase <code>window_samples</code> for finer spectral resolution.</li> </ul>"},{"location":"modules/ch04_numeric/README_3_filter/#next-steps","title":"Next steps","text":"<ul> <li>Swap the source for real audio (file or mic) and reuse the same two transforms.  </li> <li>Add a third node (e.g., <code>sklearn</code> anomaly detector) and log results to JSONL.</li> </ul>"},{"location":"modules/ch05_ds/","title":"\ud83e\udde9 Chapter 5 \u2014 Transformers for Data Science","text":""},{"location":"modules/ch05_ds/#goal","title":"\ud83c\udfaf Goal","text":"<p>Learn how to build data science blocks (like CountVectorizer, TF-IDF, KMeans, and PCA) in exactly the same way that you build GPT blocks or other types of blocks.</p>"},{"location":"modules/ch05_ds/#requirements","title":"\ud83d\udce6 Requirements","text":"<p>Before running these examples, make sure your Python virtual environment has the right packages installed:</p> <pre><code># Activate your venv first\nsource venv/bin/activate   # Mac/Linux\n.\\venv\\Scripts\\activate    # Windows PowerShell\n\n# Then install dependencies\npip install scikit-learn matplotlib\n</code></pre>"},{"location":"modules/ch05_ds/#what-well-build","title":"\ud83d\udccd What We\u2019ll Build","text":"<p>We\u2019ll explore two parts:</p> <ol> <li> <p>Part 1 \u2014 Simple Word Counts + KMeans    Use a generator of short movie reviews \u2192 count words \u2192 cluster into groups.</p> </li> <li> <p>Part 2 \u2014 TF-IDF + PCA + KMeans    Scale up with TF-IDF and dimensionality reduction for richer clusters and visualizations.</p> </li> </ol> <p>Visual: <code>[ Generator ] \u2192 [ Vectorizer ] \u2192 [ Clusterer ] \u2192 [ Plot Recorder ]</code></p>"},{"location":"modules/ch05_ds/#part-1-simple-word-counts-kmeans","title":"\ud83d\udcbb Part 1 \u2014 Simple Word Counts + KMeans","text":"<p>We\u2019ll use <code>CountVectorizer</code> to turn reviews into counts of words like <code>\"good\"</code> and <code>\"bad\"</code>, and then cluster into 2 groups using KMeans.  </p> <p>Code: </p> <pre><code># dsl/examples/ch05_ds/part1_counts_kmeans.py\n\nimport sklearn.feature_extraction.text as text      # text vectorizers live here\nimport sklearn.cluster as cluster                   # clustering algorithms live here\nimport matplotlib.pyplot as plt                     # plotting library\n\nfrom dsl.core import Network\nfrom dsl.block_lib.stream_generators import GenerateFromList\nfrom dsl.block_lib.stream_transformers import WrapFunction\nfrom dsl.block_lib.stream_recorders import RecordToList\n\n# --- Sample movie reviews ---\nreviews = [\n    \"The movie was good and enjoyable\",\n    \"Really bad acting and poor script\",\n    \"Good fun with friends\",\n    \"Terrible and bad experience\",\n    \"An excellent and good film\"\n]\n\n# Store outputs (each element will be a dict with vector + cluster)\nresults = []\n\n# --- Define transformers ---\n# Count how many times words \"good\" and \"bad\" appear\nvectorizer = text.CountVectorizer(vocabulary=[\"good\", \"bad\"])\n\n# Group reviews into 2 clusters\nkmeans = cluster.KMeans(n_clusters=2, random_state=42)\n\ndef vectorize(single_review: str):\n    \"\"\"Turn one review into a count vector [count_good, count_bad].\"\"\"\n    return vectorizer.transform([single_review]).toarray()\n\ndef cluster_one(vector):\n    \"\"\"Cluster one vector into group 0 or 1.\"\"\"\n    return kmeans.fit_predict(vector)\n\n# --- Build network ---\nnet = Network(\n    blocks={\n        \"generator\": GenerateFromList(items=reviews, key=\"text\"),\n        \"vectorizer\": WrapFunction(\n            func=lambda x: vectorize(x),\n            input_key=\"text\",\n            output_key=\"vector\"\n        ),\n        \"cluster\": WrapFunction(\n            func=lambda v: int(cluster_one(v)[0]),\n            input_key=\"vector\",\n            output_key=\"cluster\"\n        ),\n        \"recorder\": RecordToList(results),\n    },\n    connections=[\n        (\"generator\", \"out\", \"vectorizer\", \"in\"),\n        (\"vectorizer\", \"out\", \"cluster\", \"in\"),\n        (\"cluster\", \"out\", \"recorder\", \"in\"),\n    ]\n)\n\nnet.compile_and_run()\nprint(\"Results:\", results)\n\n# --- Visualization ---\n# Each result dict has {\"vector\": [good_count, bad_count], \"cluster\": c}\nvectors = [r[\"vector\"][0] for r in results]\nclusters = [r[\"cluster\"] for r in results]\n\nxs = [v[0] for v in vectors]  # count of \"good\"\nys = [v[1] for v in vectors]  # count of \"bad\"\n\nplt.scatter(xs, ys, c=clusters, cmap=\"coolwarm\", s=80)\nplt.xlabel(\"count('good')\")\nplt.ylabel(\"count('bad')\")\nplt.title(\"Clusters of Reviews (CountVectorizer + KMeans)\")\nplt.savefig(\"part1_plot.svg\")\nplt.show()\n</code></pre> <p>What you\u2019ll see: \ud83d\udcca A scatter plot where x = count('good'), y = count('bad'), colored by cluster.</p>"},{"location":"modules/ch05_ds/#part-2-real-bag-of-words-tf-idf-pca-kmeans","title":"\ud83d\udcbb Part 2 \u2014 Real Bag-of-Words (TF-IDF + PCA + KMeans)","text":"<p>We scale up to TF-IDF (lots of words), cluster with KMeans, and then project to 2D with PCA so we can see it.</p> <p>Code:</p> <pre><code># dsl/examples/ch05_ds/part2_tfidf_pca_kmeans.py\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nfrom dsl.core import Network\nfrom dsl.block_lib.stream_generators import GenerateFromList\nfrom dsl.block_lib.stream_transformers import WrapFunction\nfrom dsl.block_lib.stream_recorders import RecordToList\n\n# Reviews (same as Part 1)\nreviews = [\n    \"The movie was good and enjoyable\",\n    \"Really bad acting and poor script\",\n    \"Good fun with friends\",\n    \"Terrible and bad experience\",\n    \"An excellent and good film\"\n]\n\nresults = []\n\n# Define transformers\nvectorizer = TfidfVectorizer()\nkmeans = KMeans(n_clusters=2, random_state=42)\npca = PCA(n_components=2)\n\ndef vectorize(texts):\n    return vectorizer.fit_transform(texts).toarray()\n\ndef cluster(vectors):\n    return kmeans.fit_predict(vectors)\n\ndef reduce(vectors):\n    return pca.fit_transform(vectors)\n\nnet = Network(\n    blocks={\n        \"generator\": GenerateFromList(items=reviews, key=\"text\"),\n        \"vectorizer\": WrapFunction(func=lambda _: vectorizer.fit_transform(reviews).toarray(), input_key=\"text\", output_key=\"vectors\"),\n        \"cluster\": WrapFunction(func=lambda v: int(cluster([v])[0]), input_key=\"vectors\", output_key=\"cluster\"),\n        \"recorder\": RecordToList(results),\n    },\n    connections=[\n        (\"generator\", \"out\", \"vectorizer\", \"in\"),\n        (\"vectorizer\", \"out\", \"cluster\", \"in\"),\n        (\"cluster\", \"out\", \"recorder\", \"in\"),\n    ]\n)\n\nnet.compile_and_run()\nprint(results)\n\n# Now do PCA on the full set\nX = vectorizer.fit_transform(reviews).toarray()\nX2d = pca.fit_transform(X)\nclusters = kmeans.fit_predict(X)\n\nplt.scatter(X2d[:, 0], X2d[:, 1], c=clusters, cmap=\"coolwarm\", s=80)\nplt.xlabel(\"PCA 1\")\nplt.ylabel(\"PCA 2\")\nplt.title(\"Clusters of Reviews (TF-IDF + PCA + KMeans)\")\nplt.savefig(\"part2_plot.svg\")\nplt.show()\n</code></pre> <p>What you\u2019ll see: \ud83d\udcca A scatter plot in 2D (PCA projection), with points colored by cluster.</p> <p>\u26a0\ufe0f Tip for running plots When <code>plt.show()</code> runs, a plot window will open. The Python program pauses until you close the window. - On most systems, click the \u274c close button. - If you\u2019re running in some terminals, you may need to press Ctrl-C to break out.  </p>"},{"location":"modules/ch05_ds/#key-takeaways","title":"\u2705 Key Takeaways","text":"<ul> <li> <p>The two core ideas -- (1) blocks execute functions that process messages and (2) connections specify the flow of messages between blocks -- can be used for data science applications in exactly the same way as they are used for GPT and other applications.</p> </li> <li> <p>Vectorizers (Count, TF-IDF) turn text into numeric vectors; KMeans groups messages into clusters; PCA lets us see high-dimensional vectors in 2D plots. More about this in related chapters</p> </li> </ul>"},{"location":"modules/ch05_ds/#coming-up","title":"\u23ed\ufe0f Coming Up","text":"<p>\u2728 What if you wanted a distributed application that connected to external objects such as your calendar, email, shopping apps, or GitHub? The next chapter describe blocks that connect to external applications.</p> <p>\ud83d\udc49 Next up: Chapter 6 \u2014 Connectors</p>"},{"location":"modules/ch05_ds/hw_tf_idf_pca_kmeans/","title":"\ud83e\udde9 Chapter 5 \u2014 Homework: TF\u2011IDF + PCA + KMeans","text":""},{"location":"modules/ch05_ds/hw_tf_idf_pca_kmeans/#learning-objectives","title":"\ud83c\udfaf Learning Objectives","text":"<ul> <li>Build an application. </li> <li>Use TF\u2011IDF instead of simple counts to represent text numerically.</li> <li>Apply PCA to reduce dimensionality for visualization and clustering.</li> <li>Compare results against the CountVectorizer + KMeans pipeline from Part 1.</li> </ul>"},{"location":"modules/ch05_ds/hw_tf_idf_pca_kmeans/#assignment-short","title":"\ud83d\udccb Assignment (Short)","text":"<p>HW 5.1 \u2014 Replace Count with TF\u2011IDF\\ Use <code>TfidfVectorizer</code> (scikit\u2011learn) to transform the same list of short movie reviews you used in Part 1. Use blocks with <code>TransformerFunction</code>.</p> <p>HW 5.2 \u2014 Add PCA (2 components)\\ Fit <code>PCA(n_components=2)</code> on the full corpus (all reviews) and transform each review to 2D.</p> <p>HW 5.3 \u2014 Cluster &amp; Visualize\\ Run <code>KMeans(n_clusters=2, random_state=42)</code> on the 2D PCA points and make a 2D scatter plot colored by cluster labels. Save the figure (e.g., <code>hw5_plot.svg</code>).</p> <p>HW 5.4 \u2014 Reflection (3\u20135 sentences)\\ Briefly compare TF\u2011IDF + PCA + KMeans vs. CountVectorizer + KMeans from Part 1:</p> <ul> <li>Do the clusters look different?</li> <li>Which representation seems more informative on these reviews, and why?</li> </ul> <p>Important: For TF\u2011IDF and PCA you must fit on the full dataset once (outside the per\u2011message transform), then use those fitted models inside your <code>TransformerFunction</code> blocks. This mirrors best practices and avoids refitting for every message.</p>"},{"location":"modules/ch05_ds/hw_tf_idf_pca_kmeans/#what-to-submit","title":"\u2705 What to Submit","text":"<ul> <li>Code file: <code>dsl/examples/ch05_ds/hw_tfidf_pca_kmeans.py</code></li> <li>Plot: <code>hw5_plot.svg</code> (or <code>.png</code>)</li> <li>Short reflection: <code>hw5_reflection.md</code> (3\u20135 sentences)</li> </ul>"},{"location":"modules/ch05_ds/hw_tf_idf_pca_kmeans/#hints","title":"\ud83e\uddf0 Hints","text":"<ul> <li>Install requirements in your venv:   <code>bash   pip install scikit-learn matplotlib</code></li> <li>Idiomatic imports for this homework:   <code>python   from sklearn.feature_extraction.text import TfidfVectorizer   from sklearn.decomposition import PCA   from sklearn.cluster import KMeans   import matplotlib.pyplot as plt</code></li> <li>Keep using your Part 1 review list (with varied counts of \"good\"/\"bad\" etc.).</li> <li>Use <code>TransformerFunction</code> throughout, consistent with Chapter 5.</li> </ul>"},{"location":"modules/ch05_ds/hw_tf_idf_pca_kmeans/#reference-solution-python-script","title":"\ud83e\uddea Reference Solution (Python Script)","text":"<p>Save as: <code>dsl/examples/ch05_ds/hw_tfidf_pca_kmeans_solution.py</code></p> <pre><code>\"\"\"\nChapter 5 Homework Solution \u2014 TF-IDF + PCA + KMeans\nPath: dsl/examples/ch05_ds/hw_tfidf_pca_kmeans_solution.py\n\nThis solution:\n- Fits TF-IDF and PCA on the full corpus ONCE (good practice)\n- Uses TransformerFunction blocks for per-item transform steps\n- Clusters in 2D PCA space and plots the result\nRequirements: scikit-learn, matplotlib\n\"\"\"\n\nfrom typing import List\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\nfrom dsl.core import Network\nfrom dsl.block_lib.stream_generators import GenerateFromList\nfrom dsl.block_lib.stream_transformers import TransformerFunction\nfrom dsl.block_lib.stream_recorders import RecordToList\n\n# --- Sample movie reviews (corrected counts and variety) ---\nreviews: List[str] = [\n    \"good fun with friends and a good ending\",              # many 'good'\n    \"bad movie, bad soundtrack, bad acting, but good date!\",# mix\n    \"really bad, bad acting and a poor script\",             # more 'bad'\n    \"good soundtrack and good jokes but some bad scenes\",   # mixed\n    \"bad pacing but a good finale\",                         # balanced\n    \"all-around good experience, good vibes, not bad\",      # mixed\n    \"bad story, bad acting, bad music, bad cinematography.\",# heavy 'bad'\n]\n\n# --- Fit models ONCE on the full corpus ---\n# TF-IDF is fitted on all reviews so that IDF weights reflect the corpus.\nvectorizer = TfidfVectorizer()\nX_all = vectorizer.fit_transform(reviews).toarray()   # shape (N, D)\n\n# Reduce to 2D with PCA for visualization and clustering\npca = PCA(n_components=2, random_state=42)\nX2d_all = pca.fit_transform(X_all)                    # shape (N, 2)\n\n# Cluster in 2D to align with the visualization space\nkmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\nkmeans.fit(X2d_all)\n\n# Storage for per-item outputs\nresults = []\n\n# --- Per-item transform functions (use fitted models) ---\ndef tfidf_single(text: str):\n    \"\"\"Transform one review using the fitted TF-IDF; returns shape (1, D).\"\"\"\n    return vectorizer.transform([text]).toarray()\n\ndef pca_single(vec):\n    \"\"\"Project a single TF-IDF row vector to 2D using fitted PCA; shape (1, 2).\"\"\"\n    return pca.transform(vec)\n\ndef cluster_single(vec2d):\n    \"\"\"Predict KMeans label (0 or 1) for a single 1x2 vector.\"\"\"\n    return int(kmeans.predict(vec2d)[0])\n\n# --- Build DisSysLab network ---\nnet = Network(\n    blocks={\n        \"gen\": GenerateFromList(items=reviews, key=\"text\"),\n        \"tfidf\": TransformerFunction(\n            func=tfidf_single, input_key=\"text\", output_key=\"tfidf\"\n        ),\n        \"pca2d\": TransformerFunction(\n            func=pca_single, input_key=\"tfidf\", output_key=\"pca2d\"\n        ),\n        \"cluster\": TransformerFunction(\n            func=cluster_single, input_key=\"pca2d\", output_key=\"cluster\"\n        ),\n        \"rec\": RecordToList(results),\n    },\n    connections=[\n        (\"gen\", \"out\", \"tfidf\", \"in\"),\n        (\"tfidf\", \"out\", \"pca2d\", \"in\"),\n        (\"pca2d\", \"out\", \"cluster\", \"in\"),\n        (\"cluster\", \"out\", \"rec\", \"in\"),\n    ],\n)\n\nnet.compile_and_run()\n\n# Inspect a couple of results\nprint(\"Example result:\", results[0])\n\n# --- Build arrays for plotting from recorded results ---\n# Each result row contains keys: tfidf (1xD), pca2d (1x2), cluster (int)\nX2d_points = [r[\"pca2d\"][0] for r in results]  # list of [x, y]\nlabels = [r[\"cluster\"] for r in results]\n\nxs = [p[0] for p in X2d_points]\nys = [p[1] for p in X2d_points]\n\nplt.scatter(xs, ys, c=labels, s=80)\nplt.xlabel(\"PCA 1\")\nplt.ylabel(\"PCA 2\")\nplt.title(\"TF-IDF \u2192 PCA (2D) \u2192 KMeans Clusters\")\nplt.savefig(\"hw5_plot.svg\")\nplt.show()  # Close the window to end the program\n</code></pre>"},{"location":"modules/ch05_ds/hw_tf_idf_pca_kmeans/#plotting-tip","title":"\u26a0\ufe0f Plotting Tip","text":"<p><code>plt.show()</code> opens a window and pauses the program until you close it. If running in a terminal without a UI, prefer saving and closing:</p> <pre><code>plt.savefig(\"hw5_plot.svg\")\nplt.close()\n</code></pre>"},{"location":"modules/ch06_connect/","title":"\ud83e\udd1d Chapter 6 \u2014 Connectors (InputConnector &amp; OutputConnector)","text":"<p>Goal: Shows you how you can connect a distributed system to external applications using two simple blocks:</p> <ul> <li>InputConnector \u2014 pulls items from an external source  and outputs the items on an outport <code>out</code>.</li> <li>OutputConnector \u2014 pushes items it receives in input port <code>in</code> to an external sink.</li> </ul>"},{"location":"modules/ch06_connect/#mental-model","title":"\ud83e\udded Mental Model","text":"<pre><code>[ Orchestrator ] --commands--&gt; [ InputConnector ] --items--&gt; [ Transformers ] --rows--&gt; [ Orchestrator ] --flush cmd--&gt; [ OutputConnector ]\n</code></pre> <ul> <li>Orchestrator decides when/what to pull and when to flush (timer/manual).</li> <li>InputConnector does a one\u2011off pull per command and emits 0..N items.</li> <li>OutputConnector accepts a <code>{\"cmd\":\"flush\", \"payload\": [...], \"meta\": {...}}</code> command and performs one external write (e.g., one GitHub commit, one Markdown file write, one sheet update).</li> </ul>"},{"location":"modules/ch06_connect/#requirements","title":"\ud83d\udce6 Requirements","text":"<pre><code>pip install PyGithub scikit-learn matplotlib\n</code></pre> <p>PyGithub is used for a single, real\u2011world demo reading from a public repo (no token needed). Everything else uses local files so students can run it immediately.</p>"},{"location":"modules/ch06_connect/#core-blocks-minimal-readable","title":"\ud83e\uddf1 Core Blocks (minimal, readable)","text":""},{"location":"modules/ch06_connect/#inputconnector-base","title":"<code>InputConnector</code> (base)","text":"<pre><code># dsl/block_lib/connectors/input_connector.py\nfrom typing import Dict, Any, Iterable\nfrom dsl.core import SimpleAgent\n\nclass InputConnector(SimpleAgent):\n    \"\"\"Command\u2011driven pull from an external source.\n    in:  command dicts like {\"cmd\":\"pull\", \"args\":{...}}\n    out: item dicts  like {\"data\": ...}\n    \"\"\"\n    def __init__(self, name=\"InputConnector\"):\n        super().__init__(name=name, inport=\"in\", outports=[\"out\", \"status\", \"error\"])\n\n    def process(self, msg: Dict[str, Any], inport=None):\n        cmd  = (msg or {}).get(\"cmd\", \"pull\")\n        args = (msg or {}).get(\"args\", {}) or {}\n        try:\n            count = 0\n            for item in self._pull(cmd, args):  # override in subclass\n                self.send({\"data\": item}, outport=\"out\")\n                count += 1\n            self.send({\"event\":\"done\",\"cmd\":cmd,\"count\":count}, outport=\"status\")\n        except Exception as e:\n            self.send({\"event\":\"error\",\"cmd\":cmd,\"message\":repr(e)}, outport=\"error\")\n\n    def _pull(self, cmd: str, args: Dict[str, Any]) -&gt; Iterable[Dict[str, Any]]:\n        raise NotImplementedError\n</code></pre>"},{"location":"modules/ch06_connect/#outputconnector-base","title":"<code>OutputConnector</code> (base)","text":"<pre><code># dsl/block_lib/connectors/output_connector.py\nfrom typing import Dict, Any, List\nfrom dsl.core import SimpleAgent\n\nclass OutputConnector(SimpleAgent):\n    \"\"\"Command\u2011driven push to an external sink.\n    in: commands like {\"cmd\":\"flush\", \"payload\":[...], \"meta\":{...}}\n    \"\"\"\n    def __init__(self, name=\"OutputConnector\"):\n        super().__init__(name=name, inport=\"in\", outports=[\"status\", \"error\"])\n\n    def process(self, msg: Dict[str, Any], inport=None):\n        cmd   = (msg or {}).get(\"cmd\")\n        meta  = (msg or {}).get(\"meta\", {}) or {}\n        try:\n            if cmd == \"flush\":\n                payload = msg.get(\"payload\", [])\n                self._flush(payload, meta)  # override in subclass\n                self.send({\"event\":\"flushed\",\"count\":len(payload)}, outport=\"status\")\n            elif cmd == \"configure\":\n                self._configure(meta)\n                self.send({\"event\":\"configured\"}, outport=\"status\")\n            else:\n                self.send({\"event\":\"error\",\"message\":f\"unknown cmd {cmd}\"}, outport=\"error\")\n        except Exception as e:\n            self.send({\"event\":\"error\",\"cmd\":cmd,\"message\":repr(e)}, outport=\"error\")\n\n    def _flush(self, payload: List[Dict[str, Any]], meta: Dict[str, Any]):\n        raise NotImplementedError\n    def _configure(self, meta: Dict[str, Any]):\n        pass\n</code></pre>"},{"location":"modules/ch06_connect/#filebased-toy-connectors-studentowned","title":"File\u2011based toy connectors (student\u2011owned)","text":"<pre><code># dsl/block_lib/connectors/input_file.py\nimport json, pathlib\nfrom typing import Dict, Any, Iterable\nfrom .input_connector import InputConnector\n\nclass InputConnectorFile(InputConnector):\n    \"\"\"Reads items from a local JSON file on command.\n    If the file holds a list, yields each element; if it's an object, yields that single object.\n    \"\"\"\n    def __init__(self, path: str, name=\"InputConnectorFile\"):\n        super().__init__(name=name)\n        self.path = pathlib.Path(path)\n\n    def _pull(self, cmd: str, args: Dict[str, Any]) -&gt; Iterable[Dict[str, Any]]:\n        obj = json.loads(self.path.read_text(encoding=\"utf-8\"))\n        if isinstance(obj, list):\n            return obj\n        return [obj]\n</code></pre> <pre><code># dsl/block_lib/connectors/output_file.py\nimport json, pathlib\nfrom typing import Dict, Any, List\nfrom .output_connector import OutputConnector\n\nclass OutputConnectorFileJSON(OutputConnector):\n    \"\"\"Writes a single JSON file on flush (payload is a list of dicts).\"\"\"\n    def __init__(self, path: str, name=\"OutputConnectorFileJSON\"):\n        super().__init__(name=name)\n        self.path = pathlib.Path(path)\n        self.path.parent.mkdir(parents=True, exist_ok=True)\n\n    def _flush(self, payload: List[Dict[str, Any]], meta: Dict[str, Any]):\n        self.path.write_text(json.dumps(payload, indent=2), encoding=\"utf-8\")\n\nclass OutputConnectorFileMarkdown(OutputConnector):\n    \"\"\"Writes a Markdown file on flush; payload is a list of rows (strings or dicts with 'row').\"\"\"\n    def __init__(self, path: str, title: str = \"Report\", name=\"OutputConnectorFileMarkdown\"):\n        super().__init__(name=name)\n        self.path = pathlib.Path(path)\n        self.title = title\n        self.path.parent.mkdir(parents=True, exist_ok=True)\n\n    def _flush(self, payload: List[Dict[str, Any]], meta: Dict[str, Any]):\n        lines = [f\"# {meta.get('title', self.title)}\", \"\"]\n        for p in payload:\n            if isinstance(p, str):\n                lines.append(p)\n            else:\n                lines.append(p.get(\"row\", str(p)))\n        self.path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n</code></pre>"},{"location":"modules/ch06_connect/#orchestrator-buffers-and-flushes","title":"Orchestrator (buffers and flushes)","text":"<pre><code># dsl/block_lib/orchestrators/buffered_orchestrator.py\nfrom typing import Dict, Any, List\nfrom dsl.core import SimpleAgent\n\nclass BufferedOrchestrator(SimpleAgent):\n    \"\"\"Buffers rows arriving on data_in; on tick_in, sends one flush command with payload.\"\"\"\n    def __init__(self, meta_builder=None, name=\"BufferedOrchestrator\"):\n        super().__init__(name=name, inport=None, outports=[\"out\"])\n        self.inports = [\"data_in\", \"tick_in\"]\n        self._buf: List[Dict[str, Any]] = []\n        self._meta_builder = meta_builder or (lambda buf: {})\n\n    def process(self, msg: Dict[str, Any], inport=None):\n        if inport == \"data_in\":\n            self._buf.append(msg)\n        elif inport == \"tick_in\":\n            meta = self._meta_builder(self._buf)\n            self.send({\"cmd\":\"flush\", \"payload\": self._buf, \"meta\": meta}, outport=\"out\")\n            self._buf = []\n</code></pre>"},{"location":"modules/ch06_connect/#demo-a-toy-connectors-file-compute-file","title":"\ud83c\udfac Demo A \u2014 Toy connectors (file \u2192 compute \u2192 file)","text":"<p>Goal: Pull a JSON list of short issues, cluster them, format rows, flush once to a Markdown report.</p> <p>Data file: <code>dsl/examples/ch06_connectors/data/issues.json</code></p> <pre><code>[\n  {\"title\": \"Crash on startup\", \"body\": \"App throws exception when launched\"},\n  {\"title\": \"Feature: dark mode\", \"body\": \"Please add a dark theme\"},\n  {\"title\": \"Docs: typo in README\", \"body\": \"Small spelling mistake\"}\n]\n</code></pre> <p>Script: <code>dsl/examples/ch06_connectors/file_demo.py</code></p> <pre><code>import sklearn.feature_extraction.text as text\nimport sklearn.cluster as cluster\n\nfrom dsl.core import Network\nfrom dsl.block_lib.connectors.input_file import InputConnectorFile\nfrom dsl.block_lib.connectors.output_file import OutputConnectorFileMarkdown\nfrom dsl.block_lib.orchestrators.buffered_orchestrator import BufferedOrchestrator\nfrom dsl.block_lib.stream_transformers import TransformerFunction\n\nSRC = \"dsl/examples/ch06_connectors/data/issues.json\"\nOUT = \"dsl/examples/ch06_connectors/reports/issue_summary.md\"\n\n# Fit once on full corpus\nimport json, pathlib\nissues = json.loads(pathlib.Path(SRC).read_text())\ntexts = [f\"{i['title']} {i['body']}\" for i in issues]\nvec = text.CountVectorizer(max_features=2000).fit(texts)\nkm  = cluster.KMeans(n_clusters=2, random_state=42, n_init=10).fit(vec.transform(texts).toarray())\n\ndef vectorize(msg):\n    t = f\"{msg['data']['title']} {msg['data']['body']}\"\n    return vec.transform([t]).toarray()\n\ndef predict(v):\n    return int(km.predict(v)[0])\n\ndef to_row(msg):\n    label = \"bug\" if any(k in (msg['data']['title']+msg['data']['body']).lower() for k in [\"error\",\"crash\",\"exception\"]) else \"other\"\n    return {\"row\": f\"- **[{label}]** {msg['data']['title']}\"}\n\n# Build network\norch = BufferedOrchestrator(meta_builder=lambda buf: {\"title\": \"Issue Triage Summary\"})\n\nnet = Network(\n    blocks={\n        \"in\": InputConnectorFile(SRC),\n        \"vec\": TransformerFunction(func=vectorize, input_key=None, output_key=\"vec\"),\n        \"clu\": TransformerFunction(func=predict,   input_key=\"vec\",  output_key=\"cluster\"),\n        \"row\": TransformerFunction(func=to_row,    input_key=None,    output_key=\"row\"),\n        \"orch\": orch,\n        \"out\": OutputConnectorFileMarkdown(OUT, title=\"Issue Triage Summary\"),\n    },\n    connections=[\n        (\"in\",\"out\",\"vec\",\"in\"),\n        (\"vec\",\"out\",\"clu\",\"in\"),\n        (\"clu\",\"out\",\"row\",\"in\"),\n        (\"row\",\"out\",\"orch\",\"data_in\"),\n        (\"orch\",\"out\",\"out\",\"in\"),\n    ],\n)\n\n# Kick: send a single pull command and then a single flush command\nnet.compile()\nnet.blocks[\"in\"].process({\"cmd\":\"pull\"})\nnet.blocks[\"orch\"].process({\"tick\": True}, inport=\"tick_in\")\nprint(\"Wrote:\", OUT)\n</code></pre>"},{"location":"modules/ch06_connect/#demo-b-realworld-read-pygithub-public-repo","title":"\ud83c\udf10 Demo B \u2014 Real\u2011world read (PyGitHub, public repo)","text":"<p>Goal: small, authentic connector with no auth (public repo). Pull README text from a GitHub repo and write a local Markdown summary.</p> <p>Connector: <code>dsl/block_lib/connectors/input_github_readme.py</code></p> <pre><code>from github import Github\nfrom typing import Dict, Any, Iterable\nfrom .input_connector import InputConnector\n\nclass InputConnectorGitHubReadme(InputConnector):\n    \"\"\"Pulls README from a public GitHub repo on command.\n    args: {\"repo\": \"owner/name\", \"branch\": \"main\"}\n    emits one item: {\"text\": \"...README content...\"}\n    \"\"\"\n    def __init__(self, name=\"InputConnectorGitHubReadme\"):\n        super().__init__(name=name)\n        self.gh = Github()  # no token \u2192 public only\n\n    def _pull(self, cmd: str, args: Dict[str, Any]) -&gt; Iterable[Dict[str, Any]]:\n        repo_full = args.get(\"repo\")\n        if not repo_full:\n            raise ValueError(\"Missing 'repo' (e.g., 'pallets/flask')\")\n        repo = self.gh.get_repo(repo_full)\n        readme = repo.get_readme()\n        text = readme.decoded_content.decode(\"utf-8\", errors=\"replace\")\n        return [{\"text\": text, \"repo\": repo_full}]\n</code></pre> <p>Script: <code>dsl/examples/ch06_connectors/github_readme_demo.py</code></p> <pre><code>from dsl.core import Network\nfrom dsl.block_lib.connectors.input_github_readme import InputConnectorGitHubReadme\nfrom dsl.block_lib.connectors.output_file import OutputConnectorFileMarkdown\nfrom dsl.block_lib.orchestrators.buffered_orchestrator import BufferedOrchestrator\nfrom dsl.block_lib.stream_transformers import TransformerFunction\n\nOUT = \"dsl/examples/ch06_connectors/reports/readme_report.md\"\n\n# Tiny transformers: count lines and words\ndef summarize(msg):\n    text = msg[\"data\"][\"text\"]\n    lines = text.splitlines()\n    words = text.split()\n    return {\"row\": f\"- Repo README has {len(lines)} lines and {len(words)} words.\"}\n\norch = BufferedOrchestrator(meta_builder=lambda buf: {\"title\": \"README Summary\"})\n\nnet = Network(\n    blocks={\n        \"in\": InputConnectorGitHubReadme(),\n        \"sum\": TransformerFunction(func=summarize, input_key=None, output_key=\"row\"),\n        \"orch\": orch,\n        \"out\": OutputConnectorFileMarkdown(OUT, title=\"README Summary\"),\n    },\n    connections=[\n        (\"in\",\"out\",\"sum\",\"in\"),\n        (\"sum\",\"out\",\"orch\",\"data_in\"),\n        (\"orch\",\"out\",\"out\",\"in\"),\n    ],\n)\n\nnet.compile()\n# Pull from a public repo (no token). Try 'pallets/flask' or 'numpy/numpy'.\nnet.blocks[\"in\"].process({\"cmd\":\"pull\", \"args\": {\"repo\": \"pallets/flask\"}})\n# Single flush\nnet.blocks[\"orch\"].process({\"tick\": True}, inport=\"tick_in\")\nprint(\"Wrote:\", OUT)\n</code></pre> <p>To use private repos later, pass a token to <code>Github(token)</code> via environment variable and expose a small <code>configure</code> command.</p>"},{"location":"modules/ch06_connect/#take-away","title":"\ud83e\udde0 Take Away","text":"<ul> <li>Why connectors? They make external world I/O explicit and replaceable without changing the network shape.</li> <li>When to use StreamRecorder? For per\u2011item appends (logging, row insert). Connectors are for commanded, transactional writes like a one\u2011shot Markdown report or commit.</li> <li>Real world path: Today\u2019s GitHub demo reads public content; a graded assignment could invite students to add a token and write a report back to their fork.</li> <li>Future (MCP): An MCP client can implement the same <code>InputConnector</code>/<code>OutputConnector</code> contracts. Your networks stay the same; only the connector internals change.</li> </ul>"},{"location":"modules/ch07_SimAgn/","title":"\ud83e\udde9 Chapter 7 \u2014 Simple Agents","text":""},{"location":"modules/ch07_SimAgn/#goal","title":"\ud83c\udfaf Goal","text":""},{"location":"modules/ch07_SimAgn/#learn-how-to-use-the-simpleagent-class-to-build-generators-transformers-and-recorders-and-more-powerful-objects","title":"Learn how to use the SimpleAgent class to build generators, transformers, and recorders and more powerful objects.","text":""},{"location":"modules/ch07_SimAgn/#what-well-build","title":"\ud83d\udccd What We\u2019ll Build","text":"<p>We\u2019ll create a three-block network:</p> <ol> <li>Generator \u2013 produces a list of short text strings.  </li> <li>SimpleAgent \u2013 initialized with a reference string; then receives messages which are strings and compares the messages with the reference string and outputs a similarity score.</li> <li>Recorder \u2013 saves the results in a Python list.</li> </ol> <p>Visual: <code>[ Generator ] \u2192 [ SimpleAgent ] \u2192 [ Recorder ]</code></p>"},{"location":"modules/ch07_SimAgn/#-we-will-build-two-versions-of-the-simpleagent-the-first-uses-a-simple-measure-of-document-similarity-and-the-second-illustrates-a-variety-of-similarity-measures","title":"- We will build two versions of the SimpleAgent: the first uses a simple measure of document similarity and the second illustrates a variety of similarity measures.","text":""},{"location":"modules/ch07_SimAgn/#how-it-works","title":"\u2699\ufe0f How It Works","text":"<ul> <li>\ud83d\udd32 SimpleAgent </li> <li>A SimpleAgent has a single inport -- called \"in\" by convention -- and has an arbitrary number of outports. For example an agent that detects spam may have outports [\"ham\", \"spam\"].</li> <li>A SimpleAgent is specified by two functions: init_fn and handle_msg</li> <li>When a SimpleAgent object is instantiated its init_fn is executed. This function sets up initial values of the object's parameters and may also send messages.</li> <li>If handle_msg is not specified then the object terminates after executing init_fn. If handle_msg is specifed then the object waits to receive messages on its inport and applies the handle_msg function to the message.</li> </ul>"},{"location":"modules/ch07_SimAgn/#code-example","title":"\ud83d\udcbb Code Example","text":"<pre><code>from dsl.core import SimpleAgent\n# In this example the SimpleAgent object has a single outport called \"out\".\n# A SimpleAgent may have any number (including 0) of outports with arbitrary names.\n\n\ndef make_similarity_agent_simple(reference_sentence: str, name: str = \"SimilarityAgent(Simple)\"):\n    ref_words = set(str(reference_sentence).lower().split())\n\n    def init_fn(agent):\n      # This function initializes parameters of the object, setting up its initial state.\n      agent.state = {\"ref\": ref_words}\n\n\n    def handle_msg(agent, msg, inport=None):\n      # This function is applied to each message that the agent receives.\n      toks = set(str(msg).lower().split())\n      # Compute the overlap of msg with the reference\n      overlap = len(agent.state[\"ref\"] &amp; toks)\n      # Send msg and overlap on the outport \"out\"\n      agent.send({\"input\": str(msg), \"overlap\": overlap}, outport=\"out\")\n\n    return SimpleAgent(\n        name=name,\n        inport=\"in\",\n        outports=[\"out\"],\n        init_fn=init_fn,\n        handle_msg=handle_msg,\n    )\n\n\n# Example (starter)\nif __name__ == \"__main__\":\n    from dsl.core import Network\n    from dsl.block_lib.stream_generators import generate\n    from dsl.block_lib.stream_recorders import RecordToList\n\n    results = []\n    net = Network(\n        blocks={\n            \"gen\": generate([\"hello Jack\", \"hello there Jack\", \"goodbye there\", \"there, there, there\"]),\n            \"sim\": make_similarity_agent_simple(\"hello there\"),\n            \"rec\": RecordToList(results),\n        },\n        connections=[\n            (\"gen\", \"out\", \"sim\", \"in\"),\n            (\"sim\", \"out\", \"rec\", \"in\"),\n        ],\n    )\n\n    net.compile_and_run()\n    print(\"Results:\", results)\n</code></pre>"},{"location":"modules/ch07_SimAgn/#run-it","title":"\u25b6\ufe0f Run It","text":"<pre><code>python3 -m dsl.examples.ch01_networks.simple_network\n\n[]\n</code></pre>"},{"location":"modules/ch07_SimAgn/#expected-output","title":"\u25b6\ufe0f Expected Output","text":"<pre><code>Results: [{'input': 'hello Jack', 'overlap': 1}, {'input': 'hello there Jack', 'overlap': 2}, {'input': 'goodbye there', 'overlap': 1}, {'input': 'there, there, there', 'overlap': 1}]\n</code></pre>"},{"location":"modules/ch07_SimAgn/#key-takeaways","title":"\ud83e\udde0 Key Takeaways","text":"<ul> <li>SimpleAgent  is specified by init_fn which initializes the agent and handle_msg which is the function applied to each message received by the agent.</li> <li>It is the parent class for many classes including generators, transformers and recorders.</li> </ul>"},{"location":"modules/ch07_SimAgn/#coming-up","title":"\ud83d\ude80 Coming Up","text":"<p>You may need to create a block that receives messages on multiple inports and sends messages along multiple outports. You can use fan-in and fan-out blocks to create arbitrary networks; however you may want to create blocks with multiple inports and outports.</p> <p>\ud83d\udc49 Next up: Chapter 9. Agents.</p>"},{"location":"modules/ch07_SimAgn/#sidebar-using-simpleagent-to-learn-more-about-document-similarity","title":"Sidebar: Using SimpleAgent to Learn More about Document Similarity","text":"<p>The example shown above gives a simplistic view of document similarity; it merely counts the number of words in common between a reference document and a message. In computer science and natural language processing, researchers use many different ways to define similarity between documents. A few of them are illustrated below.</p> <pre><code>import re\nimport math\nfrom collections import Counter\nfrom dsl.core import SimpleAgent\n\n_word_re = re.compile(r\"[A-Za-z']+\")\n\n\ndef tokenize(text, stem=False):\n    toks = [t.lower() for t in _word_re.findall(str(text))]\n    if not stem:\n        return toks\n    # trivial stemmer: strip ing/ed/s\n    out = []\n    for t in toks:\n        for suf in (\"ing\", \"ed\", \"s\"):\n            if len(t) &gt; len(suf) + 2 and t.endswith(suf):\n                t = t[: -len(suf)]\n                break\n        out.append(t)\n    return out\n\n# --- similarity metrics ---\n\n\ndef overlap_count(a, b):\n    return len(set(a) &amp; set(b))\n\n\ndef jaccard(a, b):\n    A, B = set(a), set(b)\n    return len(A &amp; B) / len(A | B) if (A or B) else 1.0\n\n\ndef dice(a, b):\n    A, B = set(a), set(b)\n    return 2*len(A &amp; B)/(len(A)+len(B)) if (A or B) else 1.0\n\n\ndef cosine_tf(a, b):\n    ca, cb = Counter(a), Counter(b)\n    num = sum(ca[t]*cb[t] for t in set(ca) | set(cb))\n    den = math.sqrt(sum(v*v for v in ca.values())) * \\\n        math.sqrt(sum(v*v for v in cb.values()))\n    return 0.0 if den == 0 else num/den\n\n\ndef edit_distance(a_str, b_str):\n    a, b = a_str, b_str\n    m, n = len(a), len(b)\n    dp = list(range(n+1))\n    for i in range(1, m+1):\n        prev, dp[0] = dp[0], i\n        for j in range(1, n+1):\n            prev, dp[j] = dp[j], min(\n                dp[j] + 1,                  # deletion\n                dp[j-1] + 1,                # insertion\n                prev + (a[i-1] != b[j-1])   # substitution\n            )\n    return dp[n]\n\n\nMETRICS = {\n    \"overlap\": lambda ref, x: overlap_count(ref, x),\n    \"jaccard\": lambda ref, x: jaccard(ref, x),\n    \"dice\": lambda ref, x: dice(ref, x),\n    \"cosine\": lambda ref, x: cosine_tf(ref, x),\n    \"edit\": lambda ref, x: edit_distance(\" \".join(ref), \" \".join(x)),\n}\n\n\ndef make_similarity_agent(reference_sentence: str, *, metric=\"jaccard\", stem=False, name=\"SentenceSimilarityAgent\"):\n    ref_tokens = tokenize(reference_sentence, stem=stem)\n    metric_fn = METRICS.get(metric)\n    if metric_fn is None:\n        raise ValueError(\n            f\"Unknown metric '{metric}'. Choose from {list(METRICS)}\")\n\n    def init_fn(agent):\n        agent.state = {\"ref\": ref_tokens, \"metric\": metric, \"stem\": stem}\n        print(\n            f\"[{name}] Initialized with ref='{reference_sentence}', metric={metric}, stem={stem}\")\n\n    def handle_msg(agent, msg, inport=None):\n        toks = tokenize(msg, stem=agent.state[\"stem\"])\n        score = metric_fn(agent.state[\"ref\"], toks)\n        result = {\"input\": str(\n            msg), \"metric\": agent.state[\"metric\"], \"score\": round(score, 3)}\n        print(f\"[{name}] Input='{msg}' \u2192 {agent.state['metric']}={result['score']}\")\n        agent.send(result, outport=\"out\")\n\n    return SimpleAgent(\n        name=name,\n        inport=\"in\",\n        outports=[\"out\"],\n        init_fn=init_fn,\n        handle_msg=handle_msg,\n    )\n\n\n# Example usage\nif __name__ == \"__main__\":\n    from dsl.core import Network\n    from dsl.block_lib.stream_generators import generate\n    from dsl.block_lib.stream_recorders import RecordToList\n\n    results = []\n    net = Network(\n        blocks={\n            \"gen\": generate([\"hello Jack\", \"hello there Jack\", \"goodbye there\"], key=\"text\"),\n            \"sim\": make_similarity_agent(\"hello there\", metric=\"cosine\", stem=True),\n            \"rec\": RecordToList(results),\n        },\n        connections=[\n            (\"gen\", \"out\", \"sim\", \"in\"),\n            (\"sim\", \"out\", \"rec\", \"in\"),\n        ],\n    )\n\n    net.compile_and_run()\n    print(\"Results (Tier 2):\", results)\n</code></pre>"},{"location":"modules/ch07_connectors/README_2_RSS/","title":"2.2 RSS Sources","text":"<p>This module shows how to stream items from an RSS/Atom feed using a minimal connector: <code>RSS_In</code>. It\u2019s example-first on purpose: copy it, tweak two lines, and you\u2019ve got your own source.</p>"},{"location":"modules/ch07_connectors/README_2_RSS/#rss_in-a-connector-for-rss-is","title":"<code>RSS_In</code>: A connector for RSS is:","text":"<p>A tiny connector that: - polls an RSS/Atom URL every N seconds, - yields one dict per new entry (item mode only), - optionally fetches the linked page to attach plain <code>page_text</code>, - can prune fields via <code>output_keys</code>.</p> <p>A source has a <code>run</code> function (a zero-argument iterator) which yields dicts.  </p>"},{"location":"modules/ch07_connectors/README_2_RSS/#requirements","title":"Requirements","text":"<pre><code>pip install feedparser requests beautifulsoup4 rich\n</code></pre> <ul> <li> <p>feedparser \u2014 parse RSS/Atom feeds</p> </li> <li> <p>requests + beautifulsoup4 \u2014 (optional) fetch + extract article text</p> </li> <li> <p>rich \u2014 pretty console output for the live sink</p> </li> </ul>"},{"location":"modules/ch07_connectors/README_2_RSS/#run-the-example","title":"Run the example","text":"<p>We\u2019ll use NASA\u2019s public site feed.</p> <pre><code>python -m modules.ch02_sources.rss_NASA_simple_demo\n</code></pre> <p>After a few seconds you should see a growing list of items: title + (extracted text if enabled). If nothing shows extend life_time in the demo.</p>"},{"location":"modules/ch07_connectors/README_2_RSS/#what-it-emits","title":"What it emits","text":"<p>Each item is a small dict (exact keys depend on output_keys). Typical fields:</p> <ul> <li> <p>title: entry title</p> </li> <li> <p>link: URL to the article/post</p> </li> <li> <p>updated: feed\u2019s published/updated text (best-effort)</p> </li> <li> <p>summary: short blurb from the feed (if present)</p> </li> <li> <p>page_text: optional plain text from the linked article (when fetch_page=True)</p> </li> <li> <p>Keep messages small (3\u20136 fields) so sinks remain readable.</p> </li> </ul>"},{"location":"modules/ch07_connectors/README_2_RSS/#customize-the-demo-for-your-rss-feed","title":"Customize the demo for your RSS feed","text":"<p>Change just these parameters in rss_NASA_simple_demo:</p> <ul> <li> <p>Feed URL Replace url=\"https://www.nasa.gov/feed/\" with any RSS/Atom URL.</p> </li> <li> <p>Pace &amp; duration poll_seconds=4 (check every 4s), life_time=20 (stop after ~20s). Set life_time=None to run until you stop it.</p> </li> <li> <p>Include article text fetch_page=True to fetch and extract the linked page\u2019s text (bounded by fetch_max_bytes).</p> </li> <li> <p>Trim fields output_keys=[\"title\",\"link\",\"page_text\"] to keep the message tidy.</p> </li> </ul>"},{"location":"modules/ch07_connectors/README_2_RSS/#modify-to-build-your-own-rss-feed","title":"Modify to Build your own RSS feed.","text":"<ul> <li> <p>Duplicate the rss_in.py file and rename the class/file (e.g., MyFeed_In).</p> </li> <li> <p>Keep the interface: init(...) + run() yielding dicts.</p> </li> <li> <p>Swap the URL and fields you care about (3\u20136 fields).</p> </li> <li> <p>Add timeouts and a small byte cap (already in the example).</p> </li> </ul> <p>Quick test before connecting in the network:</p> <pre><code>for i, item in zip(range(3), rss.run()):\n    print(item)\n</code></pre>"},{"location":"modules/ch07_connectors/README_2_RSS/#using-rss-feeds","title":"Using RSS Feeds","text":"<ul> <li> <p>Set a descriptive User-Agent (with a contact email/URL) to avoid throttling.</p> </li> <li> <p>Keep poll_seconds reasonable (seconds, not milliseconds).</p> </li> <li> <p>Respect site terms; some feeds rate-limit or change formats.</p> </li> <li> <p>check usage restrictions</p> </li> </ul>"},{"location":"modules/ch07_connectors/README_2_RSS/#troubleshooting","title":"Troubleshooting","text":"<ul> <li> <p>\u201cOnly one item appears\u201d Your sink might redraw a single live panel. Use a simple print sink to verify multiple items are emitted. e.g. <code>def print_sink(v): print(v)</code> instead of using <code>kv_live_sink</code>.</p> </li> <li> <p>\u201cNothing shows up\u201d \u2022 Extend life_time, or try a busier feed. \u2022 Check network/firewall. \u2022 Temporarily set fetch_page=False to isolate feed vs. page fetch issues.</p> </li> <li> <p>Garbled text Linked pages vary. The example uses HTML parsing and strips scripts/styles.</p> </li> </ul>"},{"location":"modules/ch07_connectors/README_2_RSS/#next","title":"\ud83d\udc49 Next","text":"<p>Feeds from Social Media Posts with fanout (the output of node is connected to the inputs of two or more nodes) and fanin (the input of a node is connected to the outputs of more than one node).</p>"},{"location":"modules/ch08_agents/","title":"\ud83e\udde9 Chapter 8 \u2014 Agents (Message Security Mode)","text":""},{"location":"modules/ch08_agents/#goal","title":"\ud83c\udfaf Goal","text":"<p>Build an Agent with multiple inports/outports that changes how it processes messages when a security mode flips (e.g., <code>normal</code> \u2194 <code>virus_detected</code>). In \"virus\" mode, a checker runs on every message; in normal mode, messages pass through untouched.</p>"},{"location":"modules/ch08_agents/#what-well-build","title":"\ud83d\udccd What We\u2019ll Build","text":"<p>Inports (2):</p> <ul> <li><code>messages</code> \u2014 stream of text payloads</li> <li><code>command</code> \u2014 control messages (<code>\"normal\"</code>, <code>\"virus_detected\"</code>, optional <code>set_checker</code>)</li> </ul> <p>Outports (3):</p> <ul> <li><code>clean</code> \u2014 messages deemed safe (delivered)</li> <li><code>quarantine</code> \u2014 messages flagged by checker</li> <li><code>log</code> \u2014 status and diagnostics</li> </ul> <p>Visual</p> <pre><code> [ Msg Generator ] \u2500\u25b6 (messages)         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                     \u2502 SecuritySwitchingAgent \u2502 \u2500\u2500\u25b6 (clean)\n [ Cmd Generator ] \u2500\u2500\u25b6 (command)  \u2502                          \u2502 \u2500\u2500\u25b6 (quarantine)\n                                     \u2502                          \u2502 \u2500\u2500\u25b6 (log)\n                                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"modules/ch08_agents/#how-it-works","title":"\u2699\ufe0f How It Works","text":"<ul> <li>State: <code>{ mode: \"normal\" | \"virus\", checker: \"lenient\" | \"strict\" }</code> (default <code>normal + lenient</code>)</li> <li>Normal mode: messages go straight to <code>clean</code>.</li> <li>Virus mode: each message is scanned. If suspicious \u2192 <code>quarantine</code>; else \u2192 <code>clean</code>.</li> <li> <p>Commands:</p> </li> <li> <p><code>\"virus_detected\"</code> \u2192 switch to virus mode</p> </li> <li><code>\"normal\"</code> \u2192 switch back to normal</li> <li><code>{ \"cmd\": \"set_checker\", \"value\": \"strict\"|\"lenient\" }</code> \u2192 adjust sensitivity</li> </ul> <p>Checker (zero-deps heuristic): looks for dangerous patterns (SQL/script/system), high symbol ratio, and base64-like blobs.</p>"},{"location":"modules/ch08_agents/#example-code","title":"Example Code","text":"<pre><code># dsl/examples/ch08_agents/security_switching_agent.py\nimport re\nfrom dsl.core import Agent, Network\nfrom dsl.block_lib.stream_generators import GenerateFromList\nfrom dsl.block_lib.stream_recorders import RecordToList\n\n# --- simple heuristics (no external libs) ---\nPATTERNS = [\n    r\"\\bdrop\\s+table\\b\", r\"&lt;script\\b\", r\"\\beval\\(\", r\"\\bexec\\(\", r\"rm\\s+-rf\",\n    r\"wget\\s+http\", r\"powershell\", r\"cmd\\.exe\", r\"/bin/sh\", r\"curl\\s+http\",\n]\nDANGEROUS = [re.compile(p, re.I) for p in PATTERNS]\nBASE64_LIKE = re.compile(r\"^[A-Za-z0-9+/=]{24,}$\")\n\ndef suspicious_score(text: str):\n    t = text or \"\"\n    score = 0\n    # rule 1: direct dangerous patterns\n    if any(rx.search(t) for rx in DANGEROUS):\n        score += 2\n    # rule 2: symbol/garbage ratio\n    if len(t) &gt; 0:\n        non_alnum = sum(1 for ch in t if not ch.isalnum() and not ch.isspace())\n        if non_alnum / max(len(t),1) &gt; 0.25:\n            score += 1\n    # rule 3: long base64-like segment\n    for token in t.split():\n        if len(token) &gt;= 24 and BASE64_LIKE.match(token):\n            score += 1\n            break\n    return score\n\nTHRESHOLDS = {\"lenient\": 2, \"strict\": 1}\n\n\ndef make_security_switching_agent(name=\"SecuritySwitchingAgent\"):\n    def init_fn(agent):\n        agent.state = {\"mode\": \"normal\", \"checker\": \"lenient\"}\n        agent.send({\"event\": \"init\", **agent.state}, outport=\"log\")\n\n    def handle_msg(agent, msg, inport=None):\n        st = agent.state\n        if inport == \"command\":\n            if msg == \"virus_detected\":\n                st[\"mode\"] = \"virus\"\n                agent.send({\"event\": \"mode\", \"mode\": \"virus\"}, outport=\"log\")\n            elif msg == \"normal\":\n                st[\"mode\"] = \"normal\"\n                agent.send({\"event\": \"mode\", \"mode\": \"normal\"}, outport=\"log\")\n            elif isinstance(msg, dict) and msg.get(\"cmd\") == \"set_checker\" and msg.get(\"value\") in THRESHOLDS:\n                st[\"checker\"] = msg[\"value\"]\n                agent.send({\"event\": \"checker\", \"checker\": st[\"checker\"]}, outport=\"log\")\n            else:\n                agent.send({\"event\": \"error\", \"message\": f\"bad command: {msg}\"}, outport=\"log\")\n            return\n\n        if inport == \"messages\":\n            text = str(msg)\n            if st[\"mode\"] == \"normal\":\n                agent.send({\"text\": text, \"passed\": True, \"mode\": \"normal\"}, outport=\"clean\")\n                agent.send({\"event\": \"pass\", \"text\": text}, outport=\"log\")\n                return\n            # virus mode\n            score = suspicious_score(text)\n            thresh = THRESHOLDS[st[\"checker\"]]\n            if score &gt;= thresh:\n                agent.send({\"text\": text, \"flag\": \"suspicious\", \"score\": score}, outport=\"quarantine\")\n                agent.send({\"event\": \"quarantine\", \"score\": score}, outport=\"log\")\n            else:\n                agent.send({\"text\": text, \"passed\": True, \"mode\": \"virus\"}, outport=\"clean\")\n                agent.send({\"event\": \"pass\", \"score\": score}, outport=\"log\")\n            return\n\n        agent.send({\"event\": \"error\", \"message\": f\"unknown inport: {inport}\"}, outport=\"log\")\n\n    return Agent(\n        name=name,\n        inports=[\"messages\", \"command\"],\n        outports=[\"clean\", \"quarantine\", \"log\"],\n        init_fn=init_fn,\n        handle_msg=handle_msg,\n    )\n\n# --- demo network ---\nif __name__ == \"__main__\":\n    clean, quarantine, logs = [], [], []\n\n    msgs = [\n        \"hello world\",  # normal safe\n        \"DROP TABLE users;\",  # SQL injection-like\n        \"normal text with base64like QWxhZGRpbjpvcGVuIHNlc2FtZQ==\",  # base64-like\n        \"click here &lt;script&gt;alert('xss')&lt;/script&gt;\",  # script\n        \"just emojis!!! $$$$\",  # high symbol ratio\n    ]\n    cmds = [\"virus_detected\", {\"cmd\": \"set_checker\", \"value\": \"strict\"}, \"normal\"]\n\n    net = Network(\n        blocks={\n            \"gen_msg\": GenerateFromList(items=msgs, key=None),\n            \"gen_cmd\": GenerateFromList(items=cmds, key=None),\n            \"agent\": make_security_switching_agent(),\n            \"rec_clean\": RecordToList(clean),\n            \"rec_quar\": RecordToList(quarantine),\n            \"rec_log\": RecordToList(logs),\n        },\n        connections=[\n            (\"gen_msg\", \"out\", \"agent\", \"messages\"),\n            (\"gen_cmd\", \"out\", \"agent\", \"command\"),\n            (\"agent\", \"clean\", \"rec_clean\", \"in\"),\n            (\"agent\", \"quarantine\", \"rec_quar\", \"in\"),\n            (\"agent\", \"log\", \"rec_log\", \"in\"),\n        ],\n    )\n\n    net.compile_and_run()\n    print(\"CLEAN:\", clean)\n    print(\"QUARANTINE:\", quarantine)\n    print(\"LOGS:\", logs)\n</code></pre>"},{"location":"modules/ch08_agents/#teaching-notes","title":"Teaching Notes","text":"<ul> <li>Multiple inports/outports: <code>messages</code> vs <code>command</code>, and <code>clean</code> vs <code>quarantine</code> vs <code>log</code>.</li> <li>Asynchronous control: flip modes on-the-fly; messages keep flowing.</li> <li>Zero-dependency heuristics: rules are readable; students can add their own (hash checks, keyword lists, length thresholds).</li> <li>Extension ideas: add a <code>release_quarantine</code> command; add per-sender rate limits; maintain stats and emit periodic summaries on a <code>stats</code> outport.</li> </ul>"},{"location":"modules/ch16_fanout/","title":"\ud83d\udd00 Lesson 3 Fan-Out Blocks","text":""},{"location":"modules/ch16_fanout/#goal","title":"\ud83c\udfaf Goal","text":"<p>Build networks using fanout (one input, multiple outputs) blocks  </p>"},{"location":"modules/ch16_fanout/#what-well-build","title":"\ud83d\udccd What We\u2019ll Build","text":"<p>We will build networks with three examples of fanout blocks: broadcast, split_two_way and split_multiway.</p>"},{"location":"modules/ch16_fanout/#example-1-broadcast","title":"Example 1: Broadcast","text":"<p>Blocks in this example: - block name: \"source\"   - execution: FromList((['a', 'b', 'c'])) generates messages 'a', 'b', 'c' - block name: \"broadcast   - outports: \"out_0\", \"out_1\", \"out_2\",   - execution: Broadcast([\"out_0\", \"out_1\", \"out_2\"]), sends a copy of the stream of messages it receives from its single inport \"in\" on each of its outports. - block name: \"sink_0\", \"sink_1\", \"sink_2\"   - execution: ToList(results_0), ToList(results_1), ToList(results_1) stores the stream of messages that it receives in its inport on the specified list.</p> <pre><code># lessons.03_fanout.broadcast.py\n\nfrom dsl.kit import Network, FromList, Broadcast, ToList\n\ndef broadcast_example():\n    results_0 = []  # Holds results sent to sink_0\n    results_1 = []  # Holds results sent to sink_1\n    results_2 = []  # Holds results sent to sink_2\n\n    net = Network(\n        blocks={\n            \"source\": FromList(['a', 'b', 'c', 'd']),\n            \"broadcast\": Broadcast(outports=[\"out_0\", \"out_1\", \"out_2\"]),\n            \"sink_0\": ToList(results_0),\n            \"sink_1\": ToList(results_1),\n            \"sink_2\": ToList(results_2),\n        },\n        connections=[\n            (\"source\", \"out\", \"broadcast\", \"in\"),\n            (\"broadcast\", \"out_0\", \"sink_0\", \"in\"),\n            (\"broadcast\", \"out_1\", \"sink_1\", \"in\"),\n            (\"broadcast\", \"out_2\", \"sink_2\", \"in\"),\n        ],\n    )\n\n    net.compile_and_run()\n    assert results_0 == ['a', 'b', 'c', 'd']\n    assert results_1 == ['a', 'b', 'c', 'd']\n    assert results_2 == ['a', 'b', 'c', 'd']\n</code></pre>"},{"location":"modules/ch16_fanout/#run-it","title":"\u25b6\ufe0f Run It","text":"<pre><code>python -m lessons.03_fanout.broadcast.py\n</code></pre>"},{"location":"modules/ch16_fanout/#example-2-splitbinary","title":"Example 2 SplitBinary","text":"<p>Similar to example 1 except that Broadcast() is replaced by SplitBinary(f) where f is a boolean function that has an input message and outputs True if the message (a number) is odd. </p> <p>Blocks in this example: - block name: \"split_binary   - outports: \"out_0\", \"out_1\",   - execution: SplitBinary(f), sends the messages it receives for which f returns True on out_1 and other messages on out_0.</p> <pre><code># lessons.03_fanout.spit_binary.py\nfrom dsl.kit import Network, FromList, ToList, SplitBinary\ndef split_binary():\n    \"\"\"\n    Outport \"out_0\" receives values for which func returns False.\n    Outport \"out_1\" receives values for which func returns True.\n    Stops when any inport yields '__STOP__'.\n    \"\"\"\n    def f(x):\n        return x % 2\n\n    results_0 = []\n    results_1 = []\n    network = Network(\n        blocks={\n            \"source\": FromList([0, 1, 2, 3, 4]),\n            \"split_binary\": SplitBinary(func=f),\n            \"sink_0\": ToList(results_0),\n            \"sink_1\": ToList(results_1)\n        },\n        connections=[\n            (\"source\", \"out\", \"split_binary\", \"in\"),\n            (\"split_binary\", \"out_0\", \"sink_0\", \"in\"),\n            (\"split_binary\", \"out_1\", \"sink_1\", \"in\")\n        ]\n    )\n    network.compile_and_run()\n    assert results_0 == [0, 2, 4]\n    assert results_1 == [1, 3]\n</code></pre>"},{"location":"modules/ch16_fanout/#run-it_1","title":"\u25b6\ufe0f Run It","text":"<pre><code>python -m lessons.03_fanout.split_binary.py\n</code></pre>"},{"location":"modules/ch16_fanout/#key-takeaways","title":"\ud83e\udde0 Key Takeaways","text":"<ul> <li>You can build arbitrary networks with generators, transformers, recorders, fanout and (discussed next) fanin blocks.</li> </ul>"},{"location":"modules/ch16_fanout/#coming-up","title":"\ud83d\ude80 Coming Up","text":"<p>Fanin blocks with multiple inputs and a single output</p> <p>\ud83d\udc49 Next up: Lesson 4 \u2014 Fanin Blocks.</p>"},{"location":"modules/ch17_fanin/","title":"\ud83d\udd00 Lesson 4 Fan-In Blocks","text":""},{"location":"modules/ch17_fanin/#goal","title":"\ud83c\udfaf Goal","text":"<p>Build networks using fanin (one input, multiple outputs) blocks  </p>"},{"location":"modules/ch17_fanin/#what-well-build","title":"\ud83d\udccd What We\u2019ll Build","text":"<p>We will build networks with MergeSynch and MergeAsynch blocks which have multiple inports and a single outport called \"out\".</p>"},{"location":"modules/ch17_fanin/#example-1-synchronous-merge","title":"Example 1: Synchronous Merge","text":"<p>Blocks in this example: - block name: \"source_a   - execution: FromListDelay([\"HELLO\", \"GOOD\", \"HOW\"], delay=0.1) generates messages in the list with a delay of 0.1 seconds between messages. - block name: \"source_b   - similar to source_a sink: sink - block name: \"merge_synch   - outports: \"a\", \"b\",   - execution: MergeSynch(inports, func), waits until a message is received from each inport and then outputs func applied to the list of messages.</p> <pre><code># lessons.04_fanin.merge_synch_example\n\nfrom dsl.kit import Network, FromListDelay, ToList, MergeSynch\n\n\ndef merge_synch_example():\n\n    def f(pair):\n        return pair[0] + pair[1]\n\n    results = []\n    network = Network(\n        blocks={\n            \"source_a\": FromListDelay(items=[\"HELLO\", \"GOOD\", \"HOW\"], delay=0.1),\n            \"source_b\": FromListDelay(items=[\" world\", \" morning\", \" are you?\"], delay=0.08),\n            \"merge_synch\": MergeSynch(inports=[\"a\", \"b\"], func=f),\n            \"sink\": ToList(results)\n        },\n        connections=[\n            (\"source_a\", \"out\", \"merge_synch\", \"a\"),\n            (\"source_b\", \"out\", \"merge_synch\", \"b\"),\n            (\"merge_synch\", \"out\", \"sink\", \"in\")\n        ]\n    )\n    network.compile_and_run()\n    assert results == ['HELLO world', 'GOOD morning', 'HOW are you?']\n</code></pre>"},{"location":"modules/ch17_fanin/#run-it","title":"\u25b6\ufe0f Run It","text":"<pre><code>python -m lessons.04_fanin.merge_synch_example.py\n</code></pre>"},{"location":"modules/ch17_fanin/#example-1-asynchronous-merge","title":"Example 1: Asynchronous Merge","text":"<p>Blocks in this example: sources: source_a, source_b sink: sink - block name: \"merge_asynch   - outports: \"a\", \"b\",   - execution: MergeAsynch(inports, func), outputs func applied to the message that arrives on any port. Stops execution when STOP is received on either port.</p> <pre><code># lessons.04_fanin.merge_asynch_example\n\nfrom dsl.kit import Network, FromListDelay, ToSet, MergeAsynch\n\n\ndef merge_asynch_example():\n    \"\"\"\n\n    \"\"\"\n    def f(msg, port):\n        if port == \"a\":\n            return msg + \" \" + msg\n        else:\n            return msg + \"!!!\"\n\n    results = set()\n    network = Network(\n        blocks={\n            \"source_a\": FromListDelay(items=[\"HELLO\", \"GOOD\", \"HOW\"], delay=0.15),\n            \"source_b\": FromListDelay(items=[\" world\", \" morning\", \" are you?\"], delay=0.09),\n            \"merge_asynch\": MergeAsynch(inports=[\"a\", \"b\"], func=f),\n            \"sink\": ToSet(results)\n        },\n        connections=[\n            (\"source_a\", \"out\", \"merge_asynch\", \"a\"),\n            (\"source_b\", \"out\", \"merge_asynch\", \"b\"),\n            (\"merge_asynch\", \"out\", \"sink\", \"in\")\n        ]\n    )\n    network.compile_and_run()\n    assert results == {'HELLO HELLO', 'GOOD GOOD', 'HOW HOW',\n                       ' world!!!', ' morning!!!', ' are you?!!!'}\n</code></pre>"},{"location":"modules/ch17_fanin/#run-it_1","title":"\u25b6\ufe0f Run It","text":"<pre><code>python -m lessons.03_fanout.split_binary.py\n</code></pre>"},{"location":"modules/ch17_fanin/#key-takeaways","title":"\ud83e\udde0 Key Takeaways","text":"<ul> <li>You can build arbitrary networks with generators, transformers, recorders, fanout and (discussed next) fanin blocks.</li> </ul>"},{"location":"modules/ch17_fanin/#coming-up","title":"\ud83d\ude80 Coming Up","text":"<p>Fanin blocks with multiple inputs and a single output</p> <p>\ud83d\udc49 Next up: Lesson 4 \u2014 Fanin Blocks.</p>"},{"location":"modules/ch18_GPT/","title":"\ud83e\udde9 Chapter 4 \u2014 AI Transformers","text":""},{"location":"modules/ch18_GPT/#goal","title":"\ud83c\udfaf Goal","text":"<p>Learn that you create AI blocks in the same way that you create other types of blocks. AI blocks embody a prompt just as data-science blocks may embody functions from a data-science library such as Scikit-Learn. You create blocks of different types by embodying (or \"wrapping\") different types of functions.</p>"},{"location":"modules/ch18_GPT/#what-well-build","title":"\ud83d\udccd What We\u2019ll Build","text":"<p>We\u2019ll extend our three-block network with a GPT transformer:</p> <ul> <li>Generator \u2013 produces messages with a <code>\"text\"</code> field (short reviews).  </li> <li>GPT Transformer \u2013 uses a system prompt to analyze the text.  </li> <li>Recorder \u2013 saves the GPT-augmented messages.  </li> </ul> <p>Visual: <code>[ Generator ] \u2192 [ GPT Transformer ] \u2192 [ Recorder ]</code></p>"},{"location":"modules/ch18_GPT/#code-example","title":"\ud83d\udcbb Code Example","text":"<pre><code># dsl/examples/ch04_GPT/gpt_network.py\n\nfrom dsl.core import Network\nfrom dsl.block_lib.stream_generators import GenerateFromList\nfrom dsl.block_lib.stream_transformers import TransformerPrompt\nfrom dsl.block_lib.stream_recorders import RecordToList\n\n# Store results here\nresults = []\n\n# Define the network\nnet = Network(\n    blocks={\n        \"generator\": GenerateFromList(\n            items=[\n                \"The movie was fantastic!\",\n                \"I didn\u2019t like the food.\",\n                \"Service was slow but friendly.\"\n            ],\n            key=\"text\"\n        ),\n        \"sentiment_analyzer\": TransformerPrompt(\n            system_prompt=\"You are a sentiment rater. Output a positivity score from 0 to 10.\",\n            input_key=\"text\",\n            output_key=\"sentiment\",\n        ),\n        \"recorder\": RecordToList(results),\n    },\n    connections=[\n        (\"generator\", \"out\", \"sentiment_analyzer\", \"in\"),\n        (\"sentiment_analyzer\", \"out\", \"recorder\", \"in\"),\n    ]\n)\n\nnet.compile_and_run()\nprint(results)\n</code></pre>"},{"location":"modules/ch18_GPT/#run-it","title":"\u25b6\ufe0f Run It","text":"<pre><code>python3 -m dsl.examples.ch04_GPT.gpt_network\n</code></pre>"},{"location":"modules/ch18_GPT/#example-output","title":"\u2705 Example Output","text":"<pre><code>[\n    {\"text\": \"The movie was fantastic!\", \"sentiment\": \"9\"},\n    {\"text\": \"I didn\u2019t like the food.\", \"sentiment\": \"2\"},\n    {\"text\": \"Service was slow but friendly.\", \"sentiment\": \"6\"}\n]\n</code></pre>"},{"location":"modules/ch18_GPT/#key-takeaways","title":"\ud83e\udde0 Key Takeaways","text":"<ul> <li> <p>Different types of blocks are created by embodying (wrapping) different types of function</p> </li> <li> <p>GPT blocks embody prompts.</p> </li> </ul>"},{"location":"modules/ch18_GPT/#coming-up","title":"\u23ed\ufe0f Coming Up","text":"<p>\u2728 A key idea is that different types of blocks embody different types of functions. In this page you saw how GPT blocks embody prompts. Let's use the key idea to build data-science blocks.</p> <p>\ud83d\udc49 Next up: Chapter 5 \u2014 Data Science Blocks.</p>"},{"location":"modules/ch19_fanin_fanout/","title":"\ud83d\udd00 Chapter 3 \u2014 Fan-In and Fan-Out","text":""},{"location":"modules/ch19_fanin_fanout/#goal","title":"\ud83c\udfaf Goal","text":"<p>Learn how to build arbitrary networks using fan-out (one input, multiple outputs) and fan-in (multiple inputs, one output).  </p>"},{"location":"modules/ch19_fanin_fanout/#what-well-build","title":"\ud83d\udccd What We\u2019ll Build","text":"<p>A very simple network that splits a stream of movie reviews based on whether the reviews were positive or negative, and then modifies the positive and negative reviews in different ways, and finally merges all reviews.</p> <ul> <li>Generator \u2192 emits dicts with a <code>\"review\"</code> field.  </li> <li>Split \u2192 routes each review to <code>\"pos\"</code> or <code>\"neg\"</code>.  </li> <li>Positive branch \u2192 adds <code>\"!!!\"</code> and writes into <code>\"positive\"</code>.  </li> <li>Negative branch \u2192 uppercases text and writes into <code>\"negative\"</code>.  </li> <li>Merge \u2192 joins both branches back into one stream.  </li> <li>Recorder \u2192 saves merged dicts.</li> </ul> <p>Visual: </p> <p>`</p> <pre><code>               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n               \u2502  Generator \u2502\n               \u2502 {\"review\"} \u2502\n               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2502\n                  \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2510\n                  \u2502 Split \u2502  (routes \"pos\" or \"neg\")\n                  \u2514\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2518\n             pos \u2500\u2500\u2518   \u2514\u2500\u2500 neg\n                   \u2502       \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500-\u2510   \u250c\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500-\u2510\n         \u2502 pos_exclaim\u2502   \u2502  neg_upper \u2502\n         \u2502  + \"!!!\"   \u2502   \u2502  upper()   \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502              \u2502\n                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u250c--\u2500\u25bc\u2500--\u2510\n                   \u2502 Merge \u2502\n                   \u2514\u2500-----\u2500\u2518\n                       \u2502\n                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                \u2502   Recorder  \u2502\n                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>`</p>"},{"location":"modules/ch19_fanin_fanout/#code-example","title":"\ud83d\udcbb Code Example","text":"<p>\ud83d\udcca Diagram of blocks and connections: </p> <pre><code># dsl/examples/ch03_fanin_fanout/review_split_merge.py\n\nfrom dsl.core import Network\nfrom dsl.block_lib.generators import GenerateFromList\nfrom dsl.block_lib.transformers import TransformerFunction\nfrom dsl.block_lib.recorders import RecordToList\nfrom dsl.block_lib.fanout import Split\nfrom dsl.block_lib.fanin import MergeAsynch\n\n# --- Split function: classify review sentiment ---\ndef classify_sentiment(msg: dict) -&gt; str:\n    text = msg[\"review\"].lower()\n    if \"good\" in text or \"great\" in text:\n        return \"pos\"\n    else:\n        return \"neg\"\n\n# --- Transformer functions ---\ndef add_exclamations(x: str) -&gt; str:\n    return x + \"!!!\"\n\ndef to_upper(x: str) -&gt; str:\n    return x.upper()\n\nresults = []\n\nnet = Network(\n    blocks={\n        # Generator emits dicts: {\"review\": \"...\"}\n        \"gen\": GenerateFromList(\n            items=[\"Great movie\", \"Terrible acting\", \"Good plot\", \"Bad ending\"],\n            key=\"review\"\n        ),\n        \"split\": Split(split_function=classify_sentiment,\n                       outports=[\"pos\", \"neg\"]),\n        \"pos_exclaim\": TransformerFunction(\n            func=add_exclamations,\n            input_key=\"review\",\n            output_key=\"positive\"\n        ),\n        \"neg_upper\": TransformerFunction(\n            func=to_upper,\n            input_key=\"review\",\n            output_key=\"negative\"\n        ),\n        \"merge\": MergeAsynch(inports=[\"pos\", \"neg\"]),\n        \"rec\": RecordToList(results),\n    },\n    connections=[\n        (\"gen\", \"out\", \"split\", \"in\"),\n        (\"split\", \"pos\", \"pos_exclaim\", \"in\"),\n        (\"split\", \"neg\", \"neg_upper\", \"in\"),\n        (\"pos_exclaim\", \"out\", \"merge\", \"pos\"),\n        (\"neg_upper\", \"out\", \"merge\", \"neg\"),\n        (\"merge\", \"out\", \"rec\", \"in\"),\n    ]\n)\n\nnet.compile_and_run()\nprint(results)\n</code></pre>"},{"location":"modules/ch19_fanin_fanout/#run-it","title":"\u25b6\ufe0f Run It","text":"<pre><code>python3 -m dsl.examples.ch03_fanin_fanout.review_split_merge\n</code></pre>"},{"location":"modules/ch19_fanin_fanout/#output","title":"\u2705 Output","text":"<pre><code>[\n  {\"review\": \"Great movie\", \"positive\": \"Great movie!!!\"},\n  {\"review\": \"Terrible acting\", \"negative\": \"TERRIBLE ACTING\"},\n  {\"review\": \"Good plot\", \"positive\": \"Good plot!!!\"},\n  {\"review\": \"Bad ending\", \"negative\": \"BAD ENDING\"}\n]\n</code></pre>"},{"location":"modules/ch19_fanin_fanout/#key-takeaways","title":"\ud83e\udde0 Key Takeaways","text":"<ul> <li>You can build arbitrary networks with generators, transformers, recorders, fanin and fanout blocks.</li> </ul>"},{"location":"modules/ch19_fanin_fanout/#coming-up","title":"\ud83d\ude80 Coming Up","text":"<p>You\u2019ve learned about arbitrary networks of blocks that process messages and connections that route messages between blocks. What if the blocks were AI agents? </p> <p>\ud83d\udc49 Next up: Chapter 4 \u2014 GPT Blocks.</p>"}]}